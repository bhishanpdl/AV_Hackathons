{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Description\" data-toc-modified-id=\"Description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Description</a></span></li><li><span><a href=\"#Load-the-libraries\" data-toc-modified-id=\"Load-the-libraries-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load the libraries</a></span></li><li><span><a href=\"#Load-the-data\" data-toc-modified-id=\"Load-the-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load the data</a></span></li><li><span><a href=\"#Data-Processing\" data-toc-modified-id=\"Data-Processing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Missing-values\" data-toc-modified-id=\"Missing-values-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Missing values</a></span></li><li><span><a href=\"#EDA\" data-toc-modified-id=\"EDA-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>EDA</a></span></li><li><span><a href=\"#Script\" data-toc-modified-id=\"Script-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Script</a></span></li></ul></li><li><span><a href=\"#Modelling\" data-toc-modified-id=\"Modelling-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Modelling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-validation-split\" data-toc-modified-id=\"Train-validation-split-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Train validation split</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#Xgboost\" data-toc-modified-id=\"Xgboost-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Xgboost</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "Reference: https://datahack.analyticsvidhya.com/contest/all/  \n",
    "\n",
    "\n",
    "**Predict Loan Eligibility for Dream Housing Finance company**\n",
    "Dream Housing Finance company deals in all kinds of home loans. They have presence across all urban, semi urban and rural areas. Customer first applies for home loan and after that company validates the customer eligibility for loan.\n",
    "\n",
    "Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have provided a dataset to identify the customers segments that are eligible for loan amount so that they can specifically target these customers. \n",
    "\n",
    "**Data Dictionary**\n",
    "Train file: CSV containing the customers for whom loan eligibility is known as 'Loan_Status'\n",
    "\n",
    "| Variable | Description |\n",
    "| :---|:---|\n",
    "| Loan_ID | Unique Loan ID |\n",
    "| Gender | Male/ Female |\n",
    "| Married | Applicant married (Y/N) |\n",
    "| Dependents | Number of dependents |\n",
    "| Education | Applicant Education (Graduate/ Under Graduate) |\n",
    "| Self_Employed | Self employed (Y/N) |\n",
    "| ApplicantIncome | Applicant income |\n",
    "| CoapplicantIncome | Coapplicant income |\n",
    "| LoanAmount | Loan amount in thousands |\n",
    "| Loan_Amount_Term | Term of loan in months |\n",
    "| Credit_History | credit history meets guidelines |\n",
    "| Property_Area | Urban/ Semi Urban/ Rural |\n",
    "| Loan_Status | (Target) Loan approved (Y/N) |\n",
    "\n",
    "\n",
    "**Evaluation Metric**  \n",
    "Your model performance will be evaluated on the basis of your prediction of loan status for the test data (test.csv), which contains similar data-points as train except for the loan status to be predicted. Your submission needs to be in the format as shown in sample submission.\n",
    "\n",
    "We at our end, have the actual loan status for the test dataset, against which your predictions will be evaluated. We will use the Accuracy value to judge your response.\n",
    "\n",
    "\n",
    "\n",
    "**Public and Private Split**   \n",
    "Test file is further divided into Public (25%) and Private (75%)\n",
    "\n",
    "Your initial responses will be checked and scored on the Public data.\n",
    "The final rankings would be based on your private score which will be published once the competition is over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T16:16:44.966263Z",
     "start_time": "2020-08-23T16:16:44.942975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpy', '1.18.4'), ('pandas', '1.1.0'), ('seaborn', '0.10.1')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.plotting.backend = \"matplotlib\"\n",
    "pd.set_option('max_columns',100)\n",
    "\n",
    "import time,os,json\n",
    "time_start_notebook = time.time()\n",
    "home = os.path.expanduser('~')\n",
    "SEED=100\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "[(x.__name__,x.__version__) for x in [np,pd,sns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T16:16:44.973520Z",
     "start_time": "2020-08-23T16:16:44.969424Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T16:16:44.981707Z",
     "start_time": "2020-08-23T16:16:44.977648Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T16:16:45.001695Z",
     "start_time": "2020-08-23T16:16:44.995861Z"
    }
   },
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame({\n",
    "    'Model': [],\n",
    "    'Description': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F-score': []\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T16:16:45.050115Z",
     "start_time": "2020-08-23T16:16:45.005772Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = df.copy()\n",
    "    # drop unwanted features\n",
    "    df = df.drop('Loan_ID',axis=1)\n",
    "    \n",
    "    ## try fillnan = unknown for married\n",
    "    ## I got same accuracy for xgb9.0\n",
    "#     df['Married'] = df['Married'].fillna(2)\n",
    "\n",
    "    ## try fillnan = unknown for self_employed\n",
    "    ## I got same accuracy for xgb9.0\n",
    "    df['Self_Employed'] = df['Self_Employed'].fillna(2)\n",
    "\n",
    "    # missing values imputation\n",
    "    ## fill with mode\n",
    "    cols_mode = [\n",
    "        'Married',\n",
    "        'Gender',\n",
    "        'Dependents',\n",
    "#         'Self_Employed',\n",
    "        'Credit_History']\n",
    "    for c in cols_mode:\n",
    "        df[c] = df[c].fillna(df[c].mode()[0])\n",
    "\n",
    "    ## fill with frequency\n",
    "    ## BAD!!\n",
    "#     for c in cols_mode:\n",
    "#         np.random.seed(SEED)\n",
    "#         s = df[c].value_counts(normalize=True)\n",
    "#         val = np.random.choice(s.index, p=s.values,\n",
    "#                                size=df[c].isna().sum())\n",
    "#         df.loc[df[c].isna(), c] = val\n",
    "\n",
    "    ##=====================================\n",
    "    ## fill with mean\n",
    "    cols_mean = ['LoanAmount',\n",
    "                 'Loan_Amount_Term'\n",
    "                ]\n",
    "\n",
    "    for c in cols_mean:\n",
    "        df[c] = df[c].fillna(df[c].mean())\n",
    "\n",
    "    ## fill with mean with more columns\n",
    "    ## BAD for xgb9.0\n",
    "#     other_cols = [\n",
    "#         'Gender',\n",
    "#         'Dependents',\n",
    "#         'Education',\n",
    "#         'ApplicantIncome',\n",
    "#         'Married',     \n",
    "#         'Property_Area',\n",
    "#         'Self_Employed']\n",
    "\n",
    "#     for c in cols_mean: \n",
    "#         df[c] = df.groupby(other_cols)[c].transform(\n",
    "#                      lambda x: x.fillna(x.mean()))\n",
    "    ##==============================================\n",
    "    ## Try loan term binning\n",
    "    ## This gave me same acc for xgb9.0 \n",
    "#     df['Loan_Amount_Term_Very_Short'] = df['Loan_Amount_Term'].map(\n",
    "#         lambda t: 1 if t<=60 else 0)\n",
    "#     df['Loan_Amount_Term_Short'] = df['Loan_Amount_Term'].map(\n",
    "#         lambda t: 1 if t>60 and t<180 else 0)\n",
    "#     df['Loan_Amount_Term_Long'] = df['Loan_Amount_Term'].map(\n",
    "#         lambda t: 1 if t>=180 and t<=300  else 0)\n",
    "#     df['Loan_Amount_Term_Very_Long'] = df['Loan_Amount_Term'].map(\n",
    "#         lambda t: 1 if t>300 else 0)\n",
    "#     df.drop('Loan_Amount_Term', axis=1, inplace=True)        \n",
    "        \n",
    "\n",
    "\n",
    "    # mapping string to integers\n",
    "    df['Gender'] = df['Gender'].map({'Male':1, 'Female': 0})\n",
    "    df['Married'] = df['Married'].map({'Yes':1, 'No': 0 })\n",
    "    df['Education'] = df['Education'].map({'Graduate': 1, 'Not Graduate': 0})\n",
    "    df['Self_Employed'] = df['Self_Employed'].map({'Yes':1, 'No': 0})\n",
    "    \n",
    "    \n",
    "    ## add features\n",
    "    ## BAD\n",
    "#     df['TotalIncome'] = df['ApplicantIncome'] + df['CoapplicantIncome']\n",
    "\n",
    "#     df['DebtIncomeRatio'] = df['TotalIncome'] / df['LoanAmount']\n",
    "\n",
    "\n",
    "\n",
    "    # data transformation\n",
    "#     df['LoanAmount_log'] = np.log1p(df['LoanAmount'])\n",
    "#     df = df.drop('LoanAmount',axis=1)\n",
    "    \n",
    "    # target \n",
    "    target = 'Loan_Status'\n",
    "    if target in df.columns:\n",
    "        df[target] = df[target].map({'Y':1, 'N': 0})\n",
    "\n",
    "    ## try make dependents 3+ to number 3\n",
    "    ## xgboost9.0 gives same result as OHE encoding\n",
    "#     df['Dependents'] = df['Dependents'].str.rstrip('+').astype(int)\n",
    "  \n",
    "    # one hot encoding\n",
    "    cols = [\n",
    "        'Dependents',\n",
    "        'Property_Area'\n",
    "    ]\n",
    "    df = pd.get_dummies(df,columns=cols,drop_first=True)\n",
    "    return df\n",
    "\n",
    "##===============================================================\n",
    "df_train = pd.read_csv('../data/raw/train.csv')\n",
    "df_test = pd.read_csv('../data/raw/test.csv')\n",
    "\n",
    "df_train = clean_data(df_train)\n",
    "df_test = clean_data(df_test)\n",
    "df_train_orig = df_train.copy()\n",
    "target = 'Loan_Status'\n",
    "df_Xtrain, df_Xvalid, ser_ytrain, ser_yvalid = train_test_split(\n",
    "    df_train_orig.drop(target,axis=1), df_train_orig[target],\n",
    "    test_size = 0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=df_train_orig[target]\n",
    ")\n",
    "\n",
    "ytrain = ser_ytrain.to_numpy().ravel()\n",
    "yvalid = ser_yvalid.to_numpy().ravel()\n",
    "Xtr = df_Xtrain\n",
    "ytr = ytrain\n",
    "Xvd = df_Xvalid\n",
    "yvd = yvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T16:16:45.108377Z",
     "start_time": "2020-08-23T16:16:45.053295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>default from version 0.9</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model               Description  Accuracy  Precision    Recall   F-score\n",
       "0   XGB  default from version 0.9  0.829268   0.807692  0.988235  0.888889"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default from xgboost version 0.9\n",
    "model = XGBClassifier(\n",
    "    # always same\n",
    "    tree_method='auto',\n",
    "    objective='binary:logistic',\n",
    "    random_state=100,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1,\n",
    "    base_score=0.5,\n",
    "\n",
    "    # most imp\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "\n",
    "    # subsample and colsample\n",
    "    subsample=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1, \n",
    "    colsample_bytree=1,\n",
    "\n",
    "    # tree depth\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    scale_pos_weight=1,\n",
    "    \n",
    "    # regularizaion alpha lambda gamma\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    )\n",
    "\n",
    "model.fit(Xtr,ytr)\n",
    "vd_preds = model.predict(Xvd)\n",
    "\n",
    "acc = metrics.accuracy_score(yvd, vd_preds)\n",
    "pre = metrics.precision_score(yvd, vd_preds)\n",
    "rec = metrics.recall_score(yvd, vd_preds)\n",
    "f1  = metrics.f1_score(yvd,vd_preds)\n",
    "\n",
    "row = ['XGB', 'default from version 0.9', acc, pre, rec, f1]\n",
    "df_eval.loc[len(df_eval)] = row\n",
    "df_eval = df_eval.drop_duplicates(['Model','Description'])\n",
    "df_eval.sort_values('Accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T16:16:45.114522Z",
     "start_time": "2020-08-23T16:16:45.110952Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "xgb9.0 default loanterm fill mean\n",
    "0.829268\n",
    "\n",
    "try1\n",
    "0.813008 ==> Loan_Amount_Term fillna mode **BAD!!**\n",
    "\n",
    "try2\n",
    "0.821138 ==> added two new cols: totalincome and debtratio **BAD**\n",
    "\n",
    "try3\n",
    "0.821138 ==> fillnans with frequency\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dataSc)",
   "language": "python",
   "name": "datasc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
