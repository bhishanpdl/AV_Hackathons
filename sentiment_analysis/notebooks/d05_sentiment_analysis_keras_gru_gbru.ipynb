{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "d05_sentiment_analysis_keras_gru_gbru.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBcRis_Eqlcp",
        "colab_type": "text"
      },
      "source": [
        "# Descriptions\n",
        "\n",
        "- BERT stands for Bidirectional Encoder Representations from Transformers\n",
        "- BERT was developed by researchers at Google in 2018\n",
        "- BERT is a text representation technique like Word Embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD2fbcXzywYE",
        "colab_type": "text"
      },
      "source": [
        "# Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnnS6ZIPgQuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "# capture will not print in notebook\n",
        "\n",
        "import os\n",
        "import sys\n",
        "ENV_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if ENV_COLAB:\n",
        "    ## install modules\n",
        "    !pip install -q git+https://github.com/amaiya/eli5@tfkeras_0_10_1\n",
        "    !pip install -q neptune-client neptune-contrib\n",
        "    !pip install -q scikit-plot\n",
        "\n",
        "    ## print\n",
        "    print('Environment: Google Colaboratory.')\n",
        "\n",
        "# NOTE: If we update modules in gcolab, we need to restart runtime."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4V3Djet-Gc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import neptune\n",
        "from neptunecontrib.api import log_table\n",
        "from neptunecontrib.monitoring.keras import NeptuneMonitor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWFr1c_G-IgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use your real key and DELETE the cell\n",
        "\n",
        "# neptune.init('bhishanpdl/twitter-sentiment-analysis','your_api_key')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDTa8jib6OK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "553ec6a4-ae8b-49bb-c3d1-d98f5a79fa38"
      },
      "source": [
        "# deep learning\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.losses import  binary_crossentropy, categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dropout,SpatialDropout1D\n",
        "from keras.layers import LSTM,GRU,Bidirectional\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D,GlobalMaxPooling1D\n",
        "\n",
        "import random\n",
        "SEED = 100\n",
        "tf.random.set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "versions_dl = [(x.__name__,x.__version__) for x in [tf,keras]]\n",
        "print(versions_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('tensorflow', '2.3.0'), ('keras', '2.4.3')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD0Nuj24ylsk",
        "colab_type": "text"
      },
      "source": [
        "# Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6Um2nU7yYW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b41c7d42-c639-4e52-bab0-9b52fffa7fb5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('max_colwidth',200)\n",
        "pd.set_option('max_columns',200)\n",
        "SEED = 100\n",
        "\n",
        "from pprint import pprint\n",
        "import time\n",
        "import sys\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "# nlp\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "versions_ds = [(x.__name__,x.__version__) for x in [np,pd,nltk]]\n",
        "pprint(versions_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('numpy', '1.18.5'), ('pandas', '1.0.5'), ('nltk', '3.2.5')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhcKHDJltMLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "df_eval = pd.DataFrame({\n",
        "    'Text Model': [],\n",
        "    'Params': [],\n",
        "    'Model': [],\n",
        "    'Description': [],\n",
        "    'Accuracy': [],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'F1': [],\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKgRz7rOynlY",
        "colab_type": "text"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6jzFcvlzHCN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "259a1cf7-47d8-483b-f657-50365c564577"
      },
      "source": [
        "target = 'label'\n",
        "maincol = 'tweet'\n",
        "\n",
        "p = 'https://github.com/bhishanpdl/Datasets/blob/master/AV_Hackathons/sentiment_analysis/processed/'\n",
        "df_combined = pd.read_csv(p + 'df_combined_clean.csv?raw=true')\n",
        "\n",
        "# we must convert list columns\n",
        "df_combined['tweet_lst_clean'] = df_combined['tweet_lst_clean'].apply(eval)\n",
        "df_combined['tweet_lst_clean_emoji'] = df_combined['tweet_lst_clean_emoji'].apply(eval)\n",
        "\n",
        "df_train = df_combined[~df_combined[target].isnull()]\n",
        "df_test = df_combined[df_combined[target].isnull()]\n",
        "\n",
        "print(f\"train : {df_train.shape}\")\n",
        "print(f\"test : {df_test.shape}\")\n",
        "display(df_train.head(2).append(df_train.tail(2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train : (7920, 24)\n",
            "test : (1953, 24)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_lst_clean</th>\n",
              "      <th>tweet_clean</th>\n",
              "      <th>hashtags_lst</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>total_length</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_sent</th>\n",
              "      <th>num_unique_words</th>\n",
              "      <th>num_words_title</th>\n",
              "      <th>num_uppercase</th>\n",
              "      <th>num_exclamation_marks</th>\n",
              "      <th>num_question_marks</th>\n",
              "      <th>num_punctuation</th>\n",
              "      <th>num_symbols</th>\n",
              "      <th>num_digits</th>\n",
              "      <th>avg_word_len</th>\n",
              "      <th>avg_uppercase</th>\n",
              "      <th>avg_unique</th>\n",
              "      <th>tweet_lst_clean_emoji</th>\n",
              "      <th>tweet_clean_emoji</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone</td>\n",
              "      <td>[fingerprint, pregnancy, test, android, aps, beautiful, cute, health, igers, iphoneonly, iphonesia, iphone]</td>\n",
              "      <td>fingerprint pregnancy test android aps beautiful cute health igers iphoneonly iphonesia iphone</td>\n",
              "      <td>['#fingerprint', '#Pregnancy', '#android', '#apps', '#beautiful', '#cute', '#health', '#igers', '#iphoneonly', '#iphonesia', '#iphone']</td>\n",
              "      <td>#fingerprint #Pregnancy #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone</td>\n",
              "      <td>128</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.923077</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[fingerprint, pregnancy, test, android, aps, beautiful, cute, health, iger, iphone, iphones, iphone]</td>\n",
              "      <td>fingerprint pregnancy test android aps beautiful cute health iger iphone iphones iphone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/</td>\n",
              "      <td>[finaly, transparant, silicon, case, thanks, uncle, yay, sony, xperia, sonyexperias]</td>\n",
              "      <td>finaly transparant silicon case thanks uncle yay sony xperia sonyexperias</td>\n",
              "      <td>['#yay', '#Sony', '#Xperia', '#S', '#sonyexperias…']</td>\n",
              "      <td>#yay #Sony #Xperia #S #sonyexperias…</td>\n",
              "      <td>131</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.764706</td>\n",
              "      <td>0.091603</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[finaly, trans, paran, silicon, case, thanks, uncle, yay, sony, x, peri, sony, ex, peri]</td>\n",
              "      <td>finaly trans paran silicon case thanks uncle yay sony x peri sony ex peri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7918</th>\n",
              "      <td>7918</td>\n",
              "      <td>7919</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Finally got my #smart #pocket #wifi stay connected anytime,anywhere! #ipad and #samsung #s3 #gadget # http://instagr.am/p/U-53G_vJU8/</td>\n",
              "      <td>[finaly, got, smart, pocket, wifi, stay, conected, anytimeanywhere, ipad, samsung, gadget]</td>\n",
              "      <td>finaly got smart pocket wifi stay conected anytimeanywhere ipad samsung gadget</td>\n",
              "      <td>['#smart', '#pocket', '#wifi', '#ipad', '#samsung', '#s3', '#gadget', '#']</td>\n",
              "      <td>#smart #pocket #wifi #ipad #samsung #s3 #gadget #</td>\n",
              "      <td>133</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.375000</td>\n",
              "      <td>0.037594</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[finaly, got, smart, pocket, wi, fi, stay, conected, anytime, anywhere, ipad, samsung, gadget]</td>\n",
              "      <td>finaly got smart pocket wi fi stay conected anytime anywhere ipad samsung gadget</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7919</th>\n",
              "      <td>7919</td>\n",
              "      <td>7920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Apple Barcelona!!! #Apple #Store #BCN #Barcelona #travel #iphone #selfie #fly #fun #cabincrew… http://instagram.com/p/wBApVzpCl3/</td>\n",
              "      <td>[aple, barcelona, aple, store, bcn, barcelona, travel, iphone, selfie, fly, fun, cabincrew]</td>\n",
              "      <td>aple barcelona aple store bcn barcelona travel iphone selfie fly fun cabincrew</td>\n",
              "      <td>['#Apple', '#Store', '#BCN', '#Barcelona', '#travel', '#iphone', '#selfie', '#fly', '#fun', '#cabincrew…']</td>\n",
              "      <td>#Apple #Store #BCN #Barcelona #travel #iphone #selfie #fly #fun #cabincrew…</td>\n",
              "      <td>129</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.093023</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[aple, barcelona, aple, store, n, barcelona, travel, iphone, self, ie, fly, fun, cabin, crew]</td>\n",
              "      <td>aple barcelona aple store n barcelona travel iphone self ie fly fun cabin crew</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      index    id  label  \\\n",
              "0         0     1    0.0   \n",
              "1         1     2    0.0   \n",
              "7918   7918  7919    0.0   \n",
              "7919   7919  7920    0.0   \n",
              "\n",
              "                                                                                                                                      tweet  \\\n",
              "0          #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone   \n",
              "1       Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/   \n",
              "7918  Finally got my #smart #pocket #wifi stay connected anytime,anywhere! #ipad and #samsung #s3 #gadget # http://instagr.am/p/U-53G_vJU8/   \n",
              "7919      Apple Barcelona!!! #Apple #Store #BCN #Barcelona #travel #iphone #selfie #fly #fun #cabincrew… http://instagram.com/p/wBApVzpCl3/   \n",
              "\n",
              "                                                                                                  tweet_lst_clean  \\\n",
              "0     [fingerprint, pregnancy, test, android, aps, beautiful, cute, health, igers, iphoneonly, iphonesia, iphone]   \n",
              "1                            [finaly, transparant, silicon, case, thanks, uncle, yay, sony, xperia, sonyexperias]   \n",
              "7918                   [finaly, got, smart, pocket, wifi, stay, conected, anytimeanywhere, ipad, samsung, gadget]   \n",
              "7919                  [aple, barcelona, aple, store, bcn, barcelona, travel, iphone, selfie, fly, fun, cabincrew]   \n",
              "\n",
              "                                                                                         tweet_clean  \\\n",
              "0     fingerprint pregnancy test android aps beautiful cute health igers iphoneonly iphonesia iphone   \n",
              "1                          finaly transparant silicon case thanks uncle yay sony xperia sonyexperias   \n",
              "7918                  finaly got smart pocket wifi stay conected anytimeanywhere ipad samsung gadget   \n",
              "7919                  aple barcelona aple store bcn barcelona travel iphone selfie fly fun cabincrew   \n",
              "\n",
              "                                                                                                                                 hashtags_lst  \\\n",
              "0     ['#fingerprint', '#Pregnancy', '#android', '#apps', '#beautiful', '#cute', '#health', '#igers', '#iphoneonly', '#iphonesia', '#iphone']   \n",
              "1                                                                                        ['#yay', '#Sony', '#Xperia', '#S', '#sonyexperias…']   \n",
              "7918                                                               ['#smart', '#pocket', '#wifi', '#ipad', '#samsung', '#s3', '#gadget', '#']   \n",
              "7919                               ['#Apple', '#Store', '#BCN', '#Barcelona', '#travel', '#iphone', '#selfie', '#fly', '#fun', '#cabincrew…']   \n",
              "\n",
              "                                                                                                   hashtags  \\\n",
              "0     #fingerprint #Pregnancy #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone   \n",
              "1                                                                      #yay #Sony #Xperia #S #sonyexperias…   \n",
              "7918                                                      #smart #pocket #wifi #ipad #samsung #s3 #gadget #   \n",
              "7919                            #Apple #Store #BCN #Barcelona #travel #iphone #selfie #fly #fun #cabincrew…   \n",
              "\n",
              "      total_length  num_words  num_sent  num_unique_words  num_words_title  \\\n",
              "0              128         13         1                13                2   \n",
              "1              131         17         1                17                5   \n",
              "7918           133         16         1                16                1   \n",
              "7919           129         13         1                13                5   \n",
              "\n",
              "      num_uppercase  num_exclamation_marks  num_question_marks  \\\n",
              "0                 5                      0                   0   \n",
              "1                12                      0                   0   \n",
              "7918              5                      1                   0   \n",
              "7919             12                      3                   0   \n",
              "\n",
              "      num_punctuation  num_symbols  num_digits  avg_word_len  avg_uppercase  \\\n",
              "0                   2            0           0      8.923077       0.039062   \n",
              "1                   3            0           0      6.764706       0.091603   \n",
              "7918                3            0           0      7.375000       0.037594   \n",
              "7919                2            0           0      9.000000       0.093023   \n",
              "\n",
              "      avg_unique  \\\n",
              "0            1.0   \n",
              "1            1.0   \n",
              "7918         1.0   \n",
              "7919         1.0   \n",
              "\n",
              "                                                                                     tweet_lst_clean_emoji  \\\n",
              "0     [fingerprint, pregnancy, test, android, aps, beautiful, cute, health, iger, iphone, iphones, iphone]   \n",
              "1                 [finaly, trans, paran, silicon, case, thanks, uncle, yay, sony, x, peri, sony, ex, peri]   \n",
              "7918        [finaly, got, smart, pocket, wi, fi, stay, conected, anytime, anywhere, ipad, samsung, gadget]   \n",
              "7919         [aple, barcelona, aple, store, n, barcelona, travel, iphone, self, ie, fly, fun, cabin, crew]   \n",
              "\n",
              "                                                                            tweet_clean_emoji  \n",
              "0     fingerprint pregnancy test android aps beautiful cute health iger iphone iphones iphone  \n",
              "1                   finaly trans paran silicon case thanks uncle yay sony x peri sony ex peri  \n",
              "7918         finaly got smart pocket wi fi stay conected anytime anywhere ipad samsung gadget  \n",
              "7919           aple barcelona aple store n barcelona travel iphone self ie fly fun cabin crew  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMKpFZEaCOB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "876cd3f9-7db4-42fc-870d-49c58366c176"
      },
      "source": [
        "display(df_test.head(2).append(df_test.tail(2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_lst_clean</th>\n",
              "      <th>tweet_clean</th>\n",
              "      <th>hashtags_lst</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>total_length</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_sent</th>\n",
              "      <th>num_unique_words</th>\n",
              "      <th>num_words_title</th>\n",
              "      <th>num_uppercase</th>\n",
              "      <th>num_exclamation_marks</th>\n",
              "      <th>num_question_marks</th>\n",
              "      <th>num_punctuation</th>\n",
              "      <th>num_symbols</th>\n",
              "      <th>num_digits</th>\n",
              "      <th>avg_word_len</th>\n",
              "      <th>avg_uppercase</th>\n",
              "      <th>avg_unique</th>\n",
              "      <th>tweet_lst_clean_emoji</th>\n",
              "      <th>tweet_clean_emoji</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7920</th>\n",
              "      <td>0</td>\n",
              "      <td>7921</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I hate the new #iphone upgrade. Won't let me download apps. #ugh #apple sucks</td>\n",
              "      <td>[hate, new, iphone, upgrade, wil, let, download, aps, ugh, aple, suck]</td>\n",
              "      <td>hate new iphone upgrade wil let download aps ugh aple suck</td>\n",
              "      <td>['#iphone', '#ugh', '#apple']</td>\n",
              "      <td>#iphone #ugh #apple</td>\n",
              "      <td>77</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.571429</td>\n",
              "      <td>0.025974</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>[hate, new, iphone, upgrade, wil, let, download, aps, ugh, aple, suck]</td>\n",
              "      <td>hate new iphone upgrade wil let download aps ugh aple suck</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7921</th>\n",
              "      <td>1</td>\n",
              "      <td>7922</td>\n",
              "      <td>NaN</td>\n",
              "      <td>currently shitting my fucking pants. #apple #iMac #cashmoney #raddest #swagswagswag http://instagr.am/p/UUIS0bIBZo/</td>\n",
              "      <td>[curently, shiting, fucking, pant, aple, imac, cashmoney, radest, swagswag]</td>\n",
              "      <td>curently shiting fucking pant aple imac cashmoney radest swagswag</td>\n",
              "      <td>['#apple', '#iMac', '#cashmoney', '#raddest', '#swagswagswag']</td>\n",
              "      <td>#apple #iMac #cashmoney #raddest #swagswagswag</td>\n",
              "      <td>115</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.545455</td>\n",
              "      <td>0.069565</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>[curently, shiting, fucking, pant, aple, imac, cash, money, rad, de, st, swag, wag, wag]</td>\n",
              "      <td>curently shiting fucking pant aple imac cash money rad de st swag wag wag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9871</th>\n",
              "      <td>1951</td>\n",
              "      <td>9872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@codeofinterest as i said #Adobe big time we may well as include #apple to</td>\n",
              "      <td>[codeofinterest, said, adobe, big, time, may, wel, include, aple]</td>\n",
              "      <td>codeofinterest said adobe big time may wel include aple</td>\n",
              "      <td>['#Adobe', '#apple']</td>\n",
              "      <td>#Adobe #apple</td>\n",
              "      <td>74</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.357143</td>\n",
              "      <td>0.013514</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>[code, interest, said, adobe, big, time, may, wel, include, aple]</td>\n",
              "      <td>code interest said adobe big time may wel include aple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9872</th>\n",
              "      <td>1952</td>\n",
              "      <td>9873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Finally I got it .. thanx my father .. #Samsung #galaxy #s3 #gift #father #phone #new http://instagr.am/p/NoxkiPE</td>\n",
              "      <td>[finaly, got, thanx, father, samsung, galaxy, gift, father, phone, new]</td>\n",
              "      <td>finaly got thanx father samsung galaxy gift father phone new</td>\n",
              "      <td>['#Samsung', '#galaxy', '#s3', '#gift', '#father', '#phone', '#new']</td>\n",
              "      <td>#Samsung #galaxy #s3 #gift #father #phone #new</td>\n",
              "      <td>113</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.705882</td>\n",
              "      <td>0.053097</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>[finaly, got, x, father, samsung, galaxy, gift, father, phone, new]</td>\n",
              "      <td>finaly got x father samsung galaxy gift father phone new</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      index    id  label  \\\n",
              "7920      0  7921    NaN   \n",
              "7921      1  7922    NaN   \n",
              "9871   1951  9872    NaN   \n",
              "9872   1952  9873    NaN   \n",
              "\n",
              "                                                                                                                    tweet  \\\n",
              "7920                                        I hate the new #iphone upgrade. Won't let me download apps. #ugh #apple sucks   \n",
              "7921  currently shitting my fucking pants. #apple #iMac #cashmoney #raddest #swagswagswag http://instagr.am/p/UUIS0bIBZo/   \n",
              "9871                                           @codeofinterest as i said #Adobe big time we may well as include #apple to   \n",
              "9872    Finally I got it .. thanx my father .. #Samsung #galaxy #s3 #gift #father #phone #new http://instagr.am/p/NoxkiPE   \n",
              "\n",
              "                                                                  tweet_lst_clean  \\\n",
              "7920       [hate, new, iphone, upgrade, wil, let, download, aps, ugh, aple, suck]   \n",
              "7921  [curently, shiting, fucking, pant, aple, imac, cashmoney, radest, swagswag]   \n",
              "9871            [codeofinterest, said, adobe, big, time, may, wel, include, aple]   \n",
              "9872      [finaly, got, thanx, father, samsung, galaxy, gift, father, phone, new]   \n",
              "\n",
              "                                                            tweet_clean  \\\n",
              "7920         hate new iphone upgrade wil let download aps ugh aple suck   \n",
              "7921  curently shiting fucking pant aple imac cashmoney radest swagswag   \n",
              "9871            codeofinterest said adobe big time may wel include aple   \n",
              "9872       finaly got thanx father samsung galaxy gift father phone new   \n",
              "\n",
              "                                                              hashtags_lst  \\\n",
              "7920                                         ['#iphone', '#ugh', '#apple']   \n",
              "7921        ['#apple', '#iMac', '#cashmoney', '#raddest', '#swagswagswag']   \n",
              "9871                                                  ['#Adobe', '#apple']   \n",
              "9872  ['#Samsung', '#galaxy', '#s3', '#gift', '#father', '#phone', '#new']   \n",
              "\n",
              "                                            hashtags  total_length  num_words  \\\n",
              "7920                             #iphone #ugh #apple            77         14   \n",
              "7921  #apple #iMac #cashmoney #raddest #swagswagswag           115         11   \n",
              "9871                                   #Adobe #apple            74         14   \n",
              "9872  #Samsung #galaxy #s3 #gift #father #phone #new           113         17   \n",
              "\n",
              "      num_sent  num_unique_words  num_words_title  num_uppercase  \\\n",
              "7920         1                14                1              2   \n",
              "7921         1                11                0              8   \n",
              "9871         1                13                1              1   \n",
              "9872         1                16                3              6   \n",
              "\n",
              "      num_exclamation_marks  num_question_marks  num_punctuation  num_symbols  \\\n",
              "7920                      0                   0                2            0   \n",
              "7921                      0                   0                3            0   \n",
              "9871                      0                   0                0            0   \n",
              "9872                      0                   0                6            0   \n",
              "\n",
              "      num_digits  avg_word_len  avg_uppercase  avg_unique  \\\n",
              "7920           0      4.571429       0.025974    1.000000   \n",
              "7921           0      9.545455       0.069565    1.000000   \n",
              "9871           0      4.357143       0.013514    0.928571   \n",
              "9872           0      5.705882       0.053097    0.941176   \n",
              "\n",
              "                                                                         tweet_lst_clean_emoji  \\\n",
              "7920                    [hate, new, iphone, upgrade, wil, let, download, aps, ugh, aple, suck]   \n",
              "7921  [curently, shiting, fucking, pant, aple, imac, cash, money, rad, de, st, swag, wag, wag]   \n",
              "9871                         [code, interest, said, adobe, big, time, may, wel, include, aple]   \n",
              "9872                       [finaly, got, x, father, samsung, galaxy, gift, father, phone, new]   \n",
              "\n",
              "                                                              tweet_clean_emoji  \n",
              "7920                 hate new iphone upgrade wil let download aps ugh aple suck  \n",
              "7921  curently shiting fucking pant aple imac cash money rad de st swag wag wag  \n",
              "9871                     code interest said adobe big time may wel include aple  \n",
              "9872                   finaly got x father samsung galaxy gift father phone new  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUNfFIMm7Rtl",
        "colab_type": "text"
      },
      "source": [
        "# Train valid split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd_dpXwu7U5v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "1d1734de-2be5-46da-a0f8-0d05989fe55e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "target = 'label'\n",
        "\n",
        "df_Xtrain, df_Xvalid, ser_ytrain, ser_yvalid = train_test_split(\n",
        "    df_train, df_train[target],\n",
        "    test_size=0.2, random_state=SEED, stratify=df_train[target])\n",
        "\n",
        "y_train = ser_ytrain.to_numpy().ravel()\n",
        "y_valid = ser_yvalid.to_numpy().ravel()\n",
        "\n",
        "print(f\"df_train   : {df_train.shape}\\n\")\n",
        "\n",
        "print(f\"df_Xtrain  : {df_Xtrain.shape}\")\n",
        "print(f\"ser_ytrain : {ser_ytrain.shape}\\n\")\n",
        "\n",
        "print(f\"df_Xvalid  : {df_Xvalid.shape}\")\n",
        "print(f\"ser_yvalid : {ser_yvalid.shape}\\n\")\n",
        "\n",
        "print(f\"df_test    : {df_test.shape}\")\n",
        "print(f\"ser_ytest  : This does not exist.\")\n",
        "\n",
        "df_Xtrain.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_train   : (7920, 24)\n",
            "\n",
            "df_Xtrain  : (6336, 24)\n",
            "ser_ytrain : (6336,)\n",
            "\n",
            "df_Xvalid  : (1584, 24)\n",
            "ser_yvalid : (1584,)\n",
            "\n",
            "df_test    : (1953, 24)\n",
            "ser_ytest  : This does not exist.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_lst_clean</th>\n",
              "      <th>tweet_clean</th>\n",
              "      <th>hashtags_lst</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>total_length</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_sent</th>\n",
              "      <th>num_unique_words</th>\n",
              "      <th>num_words_title</th>\n",
              "      <th>num_uppercase</th>\n",
              "      <th>num_exclamation_marks</th>\n",
              "      <th>num_question_marks</th>\n",
              "      <th>num_punctuation</th>\n",
              "      <th>num_symbols</th>\n",
              "      <th>num_digits</th>\n",
              "      <th>avg_word_len</th>\n",
              "      <th>avg_uppercase</th>\n",
              "      <th>avg_unique</th>\n",
              "      <th>tweet_lst_clean_emoji</th>\n",
              "      <th>tweet_clean_emoji</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>1257</td>\n",
              "      <td>1258</td>\n",
              "      <td>0.0</td>\n",
              "      <td>new iphone case. #guerlain #new #iphone #case #iphone4s #4s #pink #lapetiterobenoir it… http://instagram.com/p/YTHkSuNtTE/</td>\n",
              "      <td>[new, iphone, case, guerlain, new, iphone, case, iphones, pink, lapetiterobenoir]</td>\n",
              "      <td>new iphone case guerlain new iphone case iphones pink lapetiterobenoir</td>\n",
              "      <td>['#guerlain', '#new', '#iphone', '#case', '#iphone4s', '#4s', '#pink', '#lapetiterobenoir']</td>\n",
              "      <td>#guerlain #new #iphone #case #iphone4s #4s #pink #lapetiterobenoir</td>\n",
              "      <td>122</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.461538</td>\n",
              "      <td>0.057377</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>[new, iphone, case, gue, rla, new, iphone, case, iphone, pink, la, petite, robe, noir]</td>\n",
              "      <td>new iphone case gue rla new iphone case iphone pink la petite robe noir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1400</th>\n",
              "      <td>1400</td>\n",
              "      <td>1401</td>\n",
              "      <td>0.0</td>\n",
              "      <td>i really want an iPad for the sole reason that I just want one apple</td>\n",
              "      <td>[realy, want, ipad, sole, reason, want, one, aple]</td>\n",
              "      <td>realy want ipad sole reason want one aple</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>68</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>[realy, want, ipad, sole, reason, want, one, aple]</td>\n",
              "      <td>realy want ipad sole reason want one aple</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      index    id  label  \\\n",
              "1257   1257  1258    0.0   \n",
              "1400   1400  1401    0.0   \n",
              "\n",
              "                                                                                                                           tweet  \\\n",
              "1257  new iphone case. #guerlain #new #iphone #case #iphone4s #4s #pink #lapetiterobenoir it… http://instagram.com/p/YTHkSuNtTE/   \n",
              "1400                                                        i really want an iPad for the sole reason that I just want one apple   \n",
              "\n",
              "                                                                        tweet_lst_clean  \\\n",
              "1257  [new, iphone, case, guerlain, new, iphone, case, iphones, pink, lapetiterobenoir]   \n",
              "1400                                 [realy, want, ipad, sole, reason, want, one, aple]   \n",
              "\n",
              "                                                                 tweet_clean  \\\n",
              "1257  new iphone case guerlain new iphone case iphones pink lapetiterobenoir   \n",
              "1400                               realy want ipad sole reason want one aple   \n",
              "\n",
              "                                                                                     hashtags_lst  \\\n",
              "1257  ['#guerlain', '#new', '#iphone', '#case', '#iphone4s', '#4s', '#pink', '#lapetiterobenoir']   \n",
              "1400                                                                                           []   \n",
              "\n",
              "                                                                hashtags  \\\n",
              "1257  #guerlain #new #iphone #case #iphone4s #4s #pink #lapetiterobenoir   \n",
              "1400                                                                 NaN   \n",
              "\n",
              "      total_length  num_words  num_sent  num_unique_words  num_words_title  \\\n",
              "1257           122         13         1                13                0   \n",
              "1400            68         15         1                14                1   \n",
              "\n",
              "      num_uppercase  num_exclamation_marks  num_question_marks  \\\n",
              "1257              7                      0                   0   \n",
              "1400              2                      0                   0   \n",
              "\n",
              "      num_punctuation  num_symbols  num_digits  avg_word_len  avg_uppercase  \\\n",
              "1257                3            0           0      8.461538       0.057377   \n",
              "1400                0            0           0      3.600000       0.029412   \n",
              "\n",
              "      avg_unique  \\\n",
              "1257    1.000000   \n",
              "1400    0.933333   \n",
              "\n",
              "                                                                       tweet_lst_clean_emoji  \\\n",
              "1257  [new, iphone, case, gue, rla, new, iphone, case, iphone, pink, la, petite, robe, noir]   \n",
              "1400                                      [realy, want, ipad, sole, reason, want, one, aple]   \n",
              "\n",
              "                                                            tweet_clean_emoji  \n",
              "1257  new iphone case gue rla new iphone case iphone pink la petite robe noir  \n",
              "1400                                realy want ipad sole reason want one aple  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZBtgPv8UPOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "df_eval = pd.DataFrame({\n",
        "    'Text Model': [],\n",
        "    'Params': [],\n",
        "    'Model': [],\n",
        "    'Description': [],\n",
        "    'Accuracy': [],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'F1': [],\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT5EW1yV-xFl",
        "colab_type": "text"
      },
      "source": [
        "# Text Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6UZ9AeV-z7z",
        "colab_type": "text"
      },
      "source": [
        "## Unique words and sentence max length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQaGLCnJABgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mycol = 'tweet_clean'\n",
        "mylstcol = 'tweet_lst_clean'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrsdQYJHG9W-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = [i for i in df_Xtrain[mylstcol]]\n",
        "X_valid = [i for i in df_Xvalid[mylstcol]]\n",
        "X_test = [i for i in df_test[mylstcol]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsCpGeDp-0E2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e0c583be-df05-4e71-ff8d-5550f13c5937"
      },
      "source": [
        "unq_words = set()\n",
        "maxlen = 0\n",
        "\n",
        "for lst in tqdm(X_train):\n",
        "    unq_words.update(lst)\n",
        "    maxlen = len(lst) if maxlen < len(lst) else maxlen\n",
        "\n",
        "print(len(list(unq_words)))\n",
        "print(maxlen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 782518.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "14432\n",
            "35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBwi1ykL-0N9",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0QDt-RoH8sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "num_words = len(list(unq_words))\n",
        "tokenizer = Tokenizer(num_words=num_words)\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEJd1YS6H8wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_valid = tokenizer.texts_to_sequences(X_valid)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lZDVDdlH80j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4745afbd-6e6b-4767-b732-6135676845f6"
      },
      "source": [
        "type(X_train), X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, [4, 1, 20, 4874, 4, 1, 20, 88, 136, 4875])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SD4lJvlH87O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a70eeb9f-6aed-42fb-da22-cc0a579973bb"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_valid = sequence.pad_sequences(X_valid, maxlen=maxlen)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "\n",
        "print(X_train.shape,X_valid.shape,X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6336, 35) (1584, 35) (1953, 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yul4YugoH9Av",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f5d907c-a4fd-440b-98a6-7f9d984b319f"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iSftpXDKGTh",
        "colab_type": "text"
      },
      "source": [
        "# Neptune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9pymaJVAcX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55c143f5-107b-4a58-efc8-d5575bec5334"
      },
      "source": [
        "neptune.create_experiment(\n",
        "    name='gru_bgru', # put small name\n",
        "    description='',\n",
        "    tags = ['keras', 'gru','bgru'],\n",
        "    upload_source_files=None\n",
        ")\n",
        "\n",
        "neptune.log_text('versions_dl', str(versions_dl))\n",
        "neptune.log_text('versions_ds', str(versions_ds))\n",
        "\n",
        "neptune.log_text('mycol', mycol)\n",
        "neptune.log_text('text processing', 'tweet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://ui.neptune.ai/bhishanpdl/twitter-sentiment-analysis/e/TWITSENT-18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSd6yNCZH9ZX",
        "colab_type": "text"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1GfxDQ9J7U2",
        "colab_type": "text"
      },
      "source": [
        "## Modelling: keras GRU\n",
        "\n",
        "Ref: \n",
        "- https://docs.neptune.ai/integrations/keras.html\n",
        "- https://docs.neptune.ai/python-api/tutorials/experiment-tracking.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fQjWZdXJ-ab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from neptunecontrib.monitoring.keras import NeptuneMonitor\n",
        "\n",
        "early_stopping = EarlyStopping(min_delta = 0.001, mode = 'max',\n",
        "                               monitor='val_acc', patience=10)\n",
        "callbacks = [early_stopping,NeptuneMonitor()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2BT1PJmJ-e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "PARAMS = {'epoch_nr': 5,\n",
        "          'batch_size': 256,\n",
        "\n",
        "          'lr': 0.001,\n",
        "          'dropout': 0.2}\n",
        "\n",
        "for k,v in PARAMS.items():\n",
        "    neptune.log_metric(k,v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEC26A9_J-l2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "2fa42eff-c7a8-414e-f4e9-41ecb9c4ad9e"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# input_dim=num_words and output_dim=300\n",
        "model.add(Embedding(num_words,300,\n",
        "                    input_length=maxlen))\n",
        "\n",
        "model.add(GRU(units=128,\n",
        "               dropout=PARAMS['dropout'],\n",
        "               recurrent_dropout=PARAMS['dropout'],\n",
        "               return_sequences=True))\n",
        "\n",
        "model.add(GRU(64,\n",
        "               dropout=PARAMS['dropout'],\n",
        "               recurrent_dropout=PARAMS['dropout'],\n",
        "               return_sequences=False))\n",
        "\n",
        "model.add(Dense(100,activation='relu'))\n",
        "\n",
        "model.add(Dropout(PARAMS['dropout']))\n",
        "\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "# for multiclass: dense=(num_classes,softmax) and loss=sparse_xentropy\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=PARAMS['lr']),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 35, 300)           4329600   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 35, 128)           165120    \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               6500      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 4,538,569\n",
            "Trainable params: 4,538,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2XCn_HnTl1a",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the model\n",
        "- https://viscom.net2vis.uni-ulm.de/Qk4YOnbSnAByPCFE1FuO2COAXHAVJKlpZBPT7Py91rn8BpJ8FH\n",
        "\n",
        "Note: hover the blocks to see the details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsJH4QvHJ-q_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "79069bc2-fc97-4b0c-a14d-caf7ed5c0eab"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    epochs=PARAMS['epoch_nr'],\n",
        "                    batch_size=PARAMS['batch_size'],\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5079 - accuracy: 0.7505WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 8s 339ms/step - loss: 0.5079 - accuracy: 0.7505 - val_loss: 0.2851 - val_accuracy: 0.8801\n",
            "Epoch 2/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.9078WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 7s 284ms/step - loss: 0.2159 - accuracy: 0.9078 - val_loss: 0.2486 - val_accuracy: 0.8939\n",
            "Epoch 3/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.9569WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 7s 280ms/step - loss: 0.1165 - accuracy: 0.9569 - val_loss: 0.3202 - val_accuracy: 0.8857\n",
            "Epoch 4/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9809WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 0.0600 - accuracy: 0.9809 - val_loss: 0.4085 - val_accuracy: 0.8775\n",
            "Epoch 5/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9910WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 7s 275ms/step - loss: 0.0318 - accuracy: 0.9910 - val_loss: 0.5065 - val_accuracy: 0.8605\n",
            "CPU times: user 56.9 s, sys: 6.2 s, total: 1min 3s\n",
            "Wall time: 44 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDNwWhFh7U-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "cc7df1d5-f604-4bc5-9007-50af437a26a7"
      },
      "source": [
        "valid_preds = model.predict_classes(X_valid)\n",
        "valid_preds = valid_preds.squeeze().tolist()\n",
        "\n",
        "text_model_name = \"gru\"\n",
        "params = str(PARAMS)\n",
        "model_name = \"\"\n",
        "desc = \"\"\n",
        "\n",
        "yvd = y_valid\n",
        "vd_preds = valid_preds\n",
        "\n",
        "acc = metrics.accuracy_score(yvd,vd_preds)\n",
        "pre = metrics.precision_score(yvd,vd_preds)\n",
        "rec = metrics.recall_score(yvd,vd_preds)\n",
        "f1 = metrics.f1_score(yvd,vd_preds,average='weighted')\n",
        "\n",
        "row = [text_model_name, params, model_name,desc]\n",
        "row = row + [acc, pre, rec, f1]\n",
        "\n",
        "df_eval.loc[len(df_eval)] = row\n",
        "df_eval = df_eval.drop_duplicates(subset=['Text Model', 'Params', 'Model', 'Description'])\n",
        "\n",
        "log_table('df_eval', df_eval)\n",
        "dic_results = {'acc':acc,\n",
        "               'precision':pre,\n",
        "               'recall':rec,\n",
        "               'f1': f1}\n",
        "\n",
        "for k,v in dic_results.items():\n",
        "    print('valid_'+k, v)\n",
        "    neptune.log_metric('valid_'+k, v)\n",
        "\n",
        "display(df_eval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-40-6565d0e9ffa3>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "valid_acc 0.860479797979798\n",
            "valid_precision 0.7421052631578947\n",
            "valid_recall 0.6962962962962963\n",
            "valid_f1 0.8589899903801318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text Model</th>\n",
              "      <th>Params</th>\n",
              "      <th>Model</th>\n",
              "      <th>Description</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.86048</td>\n",
              "      <td>0.742105</td>\n",
              "      <td>0.696296</td>\n",
              "      <td>0.85899</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Text Model                                                           Params  \\\n",
              "0        gru  {'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}   \n",
              "\n",
              "  Model Description  Accuracy  Precision    Recall       F1  \n",
              "0                     0.86048   0.742105  0.696296  0.85899  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op0S5zgzXiFc",
        "colab_type": "text"
      },
      "source": [
        "## Modelling: Bidirectional GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBloeQWadX3B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "outputId": "cb8b8b67-b67d-47ee-ead9-9c6e14a403ed"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(num_words,300,input_length=maxlen))\n",
        "\n",
        "model.add(SpatialDropout1D(0.25))\n",
        "\n",
        "model.add(Bidirectional(GRU(128,dropout=0.4,return_sequences = True)))\n",
        "\n",
        "model.add(Bidirectional(GRU(64,dropout=0.5,return_sequences = False)))\n",
        "\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=PARAMS['lr']),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "#=============== fitting the model ===================\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    epochs=PARAMS['epoch_nr'],\n",
        "                    batch_size=PARAMS['batch_size'],\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks\n",
        "                    )\n",
        "\n",
        "#=============== model evaluation =====================\n",
        "valid_preds = model.predict_classes(X_valid)\n",
        "valid_preds = valid_preds.squeeze().tolist()\n",
        "\n",
        "text_model_name = \"bgru\"\n",
        "params = str(PARAMS)\n",
        "model_name = \"\"\n",
        "desc = \"\"\n",
        "\n",
        "yvd = y_valid\n",
        "vd_preds = valid_preds\n",
        "\n",
        "acc = metrics.accuracy_score(yvd,vd_preds)\n",
        "pre = metrics.precision_score(yvd,vd_preds)\n",
        "rec = metrics.recall_score(yvd,vd_preds)\n",
        "f1 = metrics.f1_score(yvd,vd_preds,average='weighted')\n",
        "\n",
        "row = [text_model_name, params, model_name,desc]\n",
        "row = row + [acc, pre, rec, f1]\n",
        "\n",
        "df_eval.loc[len(df_eval)] = row\n",
        "df_eval = df_eval.drop_duplicates(subset=['Text Model', 'Params', 'Model', 'Description'])\n",
        "\n",
        "log_table('df_eval', df_eval)\n",
        "dic_results = {'acc':acc,\n",
        "               'precision':pre,\n",
        "               'recall':rec,\n",
        "               'f1': f1}\n",
        "\n",
        "for k,v in dic_results.items():\n",
        "    print('valid_'+k, v)\n",
        "    neptune.log_metric('valid_'+k, v)\n",
        "\n",
        "display(df_eval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 35, 300)           4329600   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, 35, 300)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 35, 256)           330240    \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 128)               123648    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 4,783,617\n",
            "Trainable params: 4,783,617\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4997 - accuracy: 0.7536WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 3s 116ms/step - loss: 0.4997 - accuracy: 0.7536 - val_loss: 0.2933 - val_accuracy: 0.8706\n",
            "Epoch 2/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2434 - accuracy: 0.8984WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 2s 73ms/step - loss: 0.2434 - accuracy: 0.8984 - val_loss: 0.2538 - val_accuracy: 0.8984\n",
            "Epoch 3/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1380 - accuracy: 0.9463WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 2s 74ms/step - loss: 0.1380 - accuracy: 0.9463 - val_loss: 0.2850 - val_accuracy: 0.8996\n",
            "Epoch 4/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9725WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 2s 74ms/step - loss: 0.0774 - accuracy: 0.9725 - val_loss: 0.3532 - val_accuracy: 0.8813\n",
            "Epoch 5/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9850WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 2s 72ms/step - loss: 0.0458 - accuracy: 0.9850 - val_loss: 0.4284 - val_accuracy: 0.8687\n",
            "valid_acc 0.8686868686868687\n",
            "valid_precision 0.7545219638242894\n",
            "valid_recall 0.7209876543209877\n",
            "valid_f1 0.8676920722375269\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text Model</th>\n",
              "      <th>Params</th>\n",
              "      <th>Model</th>\n",
              "      <th>Description</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.860480</td>\n",
              "      <td>0.742105</td>\n",
              "      <td>0.696296</td>\n",
              "      <td>0.858990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bgru</td>\n",
              "      <td>{'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.868687</td>\n",
              "      <td>0.754522</td>\n",
              "      <td>0.720988</td>\n",
              "      <td>0.867692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Text Model                                                           Params  \\\n",
              "0        gru  {'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}   \n",
              "1       bgru  {'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}   \n",
              "\n",
              "  Model Description  Accuracy  Precision    Recall        F1  \n",
              "0                    0.860480   0.742105  0.696296  0.858990  \n",
              "1                    0.868687   0.754522  0.720988  0.867692  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 19.8 s, sys: 825 ms, total: 20.6 s\n",
            "Wall time: 18.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuemEJnzesnC",
        "colab_type": "text"
      },
      "source": [
        "## Modelling: CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMR-8LYWfcAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1b43faee-27b2-4de9-a411-30b1f4e2cff1"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words,300,input_length=maxlen))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(128,kernel_size=3,padding='same',activation='relu',strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=PARAMS['lr']),\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "#=============== fitting the model ===================\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    epochs=PARAMS['epoch_nr'],\n",
        "                    batch_size=PARAMS['batch_size'],\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks\n",
        "                    )\n",
        "\n",
        "#=============== model evaluation =====================\n",
        "valid_preds = model.predict_classes(X_valid)\n",
        "valid_preds = valid_preds.squeeze().tolist()\n",
        "\n",
        "text_model_name = \"cnn\"\n",
        "params = str(PARAMS)\n",
        "model_name = \"\"\n",
        "desc = \"\"\n",
        "\n",
        "yvd = y_valid\n",
        "vd_preds = valid_preds\n",
        "\n",
        "acc = metrics.accuracy_score(yvd,vd_preds)\n",
        "pre = metrics.precision_score(yvd,vd_preds)\n",
        "rec = metrics.recall_score(yvd,vd_preds)\n",
        "f1 = metrics.f1_score(yvd,vd_preds,average='weighted')\n",
        "\n",
        "row = [text_model_name, params, model_name,desc]\n",
        "row = row + [acc, pre, rec, f1]\n",
        "\n",
        "df_eval.loc[len(df_eval)] = row\n",
        "df_eval = df_eval.drop_duplicates(subset=['Text Model', 'Params', 'Model', 'Description'])\n",
        "\n",
        "log_table('df_eval', df_eval)\n",
        "dic_results = {'acc':acc,\n",
        "               'precision':pre,\n",
        "               'recall':rec,\n",
        "               'f1': f1}\n",
        "\n",
        "for k,v in dic_results.items():\n",
        "    print('valid_'+k, v)\n",
        "    neptune.log_metric('valid_'+k, v)\n",
        "\n",
        "\n",
        "model_str = \"\"\"\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words,300,input_length=maxlen))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(128,kernel_size=3,padding='same',activation='relu',strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=PARAMS['lr']),\n",
        "              metrics=['accuracy'])\n",
        "\"\"\"\n",
        "\n",
        "neptune.log_text('cnn_model', model_str)\n",
        "\n",
        "display(df_eval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text Model</th>\n",
              "      <th>Params</th>\n",
              "      <th>Model</th>\n",
              "      <th>Description</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.860480</td>\n",
              "      <td>0.742105</td>\n",
              "      <td>0.696296</td>\n",
              "      <td>0.858990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bgru</td>\n",
              "      <td>{'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.868687</td>\n",
              "      <td>0.754522</td>\n",
              "      <td>0.720988</td>\n",
              "      <td>0.867692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cnn</td>\n",
              "      <td>{'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.871843</td>\n",
              "      <td>0.748768</td>\n",
              "      <td>0.750617</td>\n",
              "      <td>0.871895</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Text Model                                                           Params  \\\n",
              "0        gru  {'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}   \n",
              "1       bgru  {'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}   \n",
              "2        cnn  {'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}   \n",
              "\n",
              "  Model Description  Accuracy  Precision    Recall        F1  \n",
              "0                    0.860480   0.742105  0.696296  0.858990  \n",
              "1                    0.868687   0.754522  0.720988  0.867692  \n",
              "2                    0.871843   0.748768  0.750617  0.871895  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyDu0Smvg5iO",
        "colab_type": "text"
      },
      "source": [
        "# Modelling: CNN + GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUb7AzsshOBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5a8378f-c36e-4cab-9b17-ad66b8ba21a4"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words,300,input_length=maxlen))\n",
        "\n",
        "model.add(Conv1D(128,kernel_size=3,padding='same',activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(GRU(256,return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=PARAMS['lr']),\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "#=============== fitting the model ===================\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    epochs=PARAMS['epoch_nr'],\n",
        "                    batch_size=PARAMS['batch_size'],\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks\n",
        "                    )\n",
        "\n",
        "#=============== model evaluation =====================\n",
        "valid_preds = model.predict_classes(X_valid)\n",
        "valid_preds = valid_preds.squeeze().tolist()\n",
        "\n",
        "text_model_name = \"cnn+gru\"\n",
        "params = str(PARAMS)\n",
        "model_name = \"\"\n",
        "desc = \"\"\n",
        "\n",
        "yvd = y_valid\n",
        "vd_preds = valid_preds\n",
        "\n",
        "acc = metrics.accuracy_score(yvd,vd_preds)\n",
        "pre = metrics.precision_score(yvd,vd_preds)\n",
        "rec = metrics.recall_score(yvd,vd_preds)\n",
        "f1 = metrics.f1_score(yvd,vd_preds,average='weighted')\n",
        "\n",
        "row = [text_model_name, params, model_name,desc]\n",
        "row = row + [acc, pre, rec, f1]\n",
        "\n",
        "df_eval.loc[len(df_eval)] = row\n",
        "df_eval = df_eval.drop_duplicates(subset=['Text Model', 'Params', 'Model', 'Description'])\n",
        "\n",
        "log_table('df_eval', df_eval)\n",
        "dic_results = {'acc':acc,\n",
        "               'precision':pre,\n",
        "               'recall':rec,\n",
        "               'f1': f1}\n",
        "\n",
        "for k,v in dic_results.items():\n",
        "    print('valid_'+k, v)\n",
        "    neptune.log_metric('valid_'+k, v)\n",
        "\n",
        "\n",
        "model_str = \"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "neptune.log_text('deeplr_model', model_str)\n",
        "\n",
        "display(df_eval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 35, 300)           4329600   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 35, 128)           115328    \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 17, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 17, 128)           0         \n",
            "_________________________________________________________________\n",
            "gru_8 (GRU)                  (None, 17, 256)           296448    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 17, 256)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4352)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               1114368   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 5,856,001\n",
            "Trainable params: 5,856,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4687 - accuracy: 0.7726WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 2s 75ms/step - loss: 0.4687 - accuracy: 0.7726 - val_loss: 0.2877 - val_accuracy: 0.8769\n",
            "Epoch 2/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1936 - accuracy: 0.9195WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 2s 62ms/step - loss: 0.1936 - accuracy: 0.9195 - val_loss: 0.2872 - val_accuracy: 0.8864\n",
            "Epoch 3/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9705WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 2s 63ms/step - loss: 0.0832 - accuracy: 0.9705 - val_loss: 0.3996 - val_accuracy: 0.8611\n",
            "Epoch 4/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9893WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 2s 61ms/step - loss: 0.0354 - accuracy: 0.9893 - val_loss: 0.5082 - val_accuracy: 0.8674\n",
            "Epoch 5/5\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9946WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "25/25 [==============================] - 2s 63ms/step - loss: 0.0139 - accuracy: 0.9946 - val_loss: 0.6212 - val_accuracy: 0.8687\n",
            "valid_acc 0.8686868686868687\n",
            "valid_precision 0.738498789346247\n",
            "valid_recall 0.7530864197530864\n",
            "valid_f1 0.8691054749755264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text Model</th>\n",
              "      <th>Params</th>\n",
              "      <th>Model</th>\n",
              "      <th>Description</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.860480</td>\n",
              "      <td>0.742105</td>\n",
              "      <td>0.696296</td>\n",
              "      <td>0.858990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bgru</td>\n",
              "      <td>{'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.868687</td>\n",
              "      <td>0.754522</td>\n",
              "      <td>0.720988</td>\n",
              "      <td>0.867692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cnn</td>\n",
              "      <td>{'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.871843</td>\n",
              "      <td>0.748768</td>\n",
              "      <td>0.750617</td>\n",
              "      <td>0.871895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cnn+gru</td>\n",
              "      <td>{'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.868687</td>\n",
              "      <td>0.738499</td>\n",
              "      <td>0.753086</td>\n",
              "      <td>0.869105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Text Model                                                           Params  \\\n",
              "0        gru  {'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}   \n",
              "1       bgru  {'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}   \n",
              "2        cnn  {'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}   \n",
              "3    cnn+gru  {'epoch_nr': 5, 'batch_size': 256, 'lr': 0.001, 'dropout': 0.2}   \n",
              "\n",
              "  Model Description  Accuracy  Precision    Recall        F1  \n",
              "0                    0.860480   0.742105  0.696296  0.858990  \n",
              "1                    0.868687   0.754522  0.720988  0.867692  \n",
              "2                    0.871843   0.748768  0.750617  0.871895  \n",
              "3                    0.868687   0.738499  0.753086  0.869105  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 13.1 s, sys: 475 ms, total: 13.6 s\n",
            "Wall time: 11.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGcqUZtTgwGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}