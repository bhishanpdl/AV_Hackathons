{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c01c_sentiment_analysis_ktrain_neptune_hpo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBcRis_Eqlcp",
        "colab_type": "text"
      },
      "source": [
        "# Descriptions\n",
        "Ref:  \n",
        "- [module: ktrain](https://github.com/amaiya/ktrain)\n",
        "\n",
        "- BERT stands for Bidirectional Encoder Representations from Transformers\n",
        "- BERT was developed by researchers at Google in 2018\n",
        "- BERT is a text representation technique like Word Embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD2fbcXzywYE",
        "colab_type": "text"
      },
      "source": [
        "# Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnnS6ZIPgQuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "# capture will not print in notebook\n",
        "\n",
        "import os\n",
        "import sys\n",
        "ENV_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if ENV_COLAB:\n",
        "    ## install modules\n",
        "    !pip install -q ktrain\n",
        "    !pip install -q git+https://github.com/amaiya/eli5@tfkeras_0_10_1\n",
        "    !pip install -q neptune-client neptune-contrib\n",
        "    !pip install -q scikit-plot\n",
        "\n",
        "    ## print\n",
        "    print('Environment: Google Colaboratory.')\n",
        "\n",
        "# NOTE: If we update modules in gcolab, we need to restart runtime."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlekYkTPn1-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ad01faa-a2b9-4b29-d30a-8ab6e222c321"
      },
      "source": [
        "import tensorflow as tf\n",
        "import ktrain\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "versions_dl = [(x.__name__,x.__version__) for x in [tf, ktrain]]\n",
        "pprint(versions_dl)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('tensorflow', '2.3.0'), ('ktrain', '0.21.2')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4V3Djet-Gc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import neptune\n",
        "from neptunecontrib.api import log_table"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWFr1c_G-IgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use your real key and DELETE the cell\n",
        "\n",
        "# neptune.init('bhishanpdl/twitter-sentiment-analysis','your_api_key')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD0Nuj24ylsk",
        "colab_type": "text"
      },
      "source": [
        "# Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6Um2nU7yYW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98eee466-5479-45f0-f78c-8c61a5bb101d"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('max_colwidth',200)\n",
        "pd.set_option('max_columns',200)\n",
        "SEED = 100\n",
        "\n",
        "import time\n",
        "import sys\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "versions_ds = [(x.__name__,x.__version__) for x in [np,pd]]\n",
        "pprint(versions_ds)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('numpy', '1.18.5'), ('pandas', '1.0.5')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhcKHDJltMLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "df_eval = pd.DataFrame({\n",
        "    'Text Model': [],\n",
        "    'Params': [],\n",
        "    'Model': [],\n",
        "    'Description': [],\n",
        "    'Accuracy': [],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'F1': [],\n",
        "})"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKgRz7rOynlY",
        "colab_type": "text"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6jzFcvlzHCN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "4aa591e7-f2d8-45c9-960c-9c5fd93a86e2"
      },
      "source": [
        "target = 'label'\n",
        "maincol = 'tweet'\n",
        "\n",
        "p = 'https://github.com/bhishanpdl/Datasets/blob/master/AV_Hackathons/sentiment_analysis/processed/'\n",
        "df_combined = pd.read_csv(p + 'df_combined_clean.csv?raw=true')\n",
        "\n",
        "df_train = df_combined[~df_combined[target].isnull()]\n",
        "df_test = df_combined[df_combined[target].isnull()]\n",
        "\n",
        "print(f\"train : {df_train.shape}\")\n",
        "print(f\"test : {df_test.shape}\")\n",
        "display(df_train.head(2).append(df_train.tail(2)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train : (7920, 24)\n",
            "test : (1953, 24)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_lst_clean</th>\n",
              "      <th>tweet_clean</th>\n",
              "      <th>hashtags_lst</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>total_length</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_sent</th>\n",
              "      <th>num_unique_words</th>\n",
              "      <th>num_words_title</th>\n",
              "      <th>num_uppercase</th>\n",
              "      <th>num_exclamation_marks</th>\n",
              "      <th>num_question_marks</th>\n",
              "      <th>num_punctuation</th>\n",
              "      <th>num_symbols</th>\n",
              "      <th>num_digits</th>\n",
              "      <th>avg_word_len</th>\n",
              "      <th>avg_uppercase</th>\n",
              "      <th>avg_unique</th>\n",
              "      <th>tweet_lst_clean_emoji</th>\n",
              "      <th>tweet_clean_emoji</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone</td>\n",
              "      <td>['fingerprint', 'pregnancy', 'test', 'android', 'aps', 'beautiful', 'cute', 'health', 'igers', 'iphoneonly', 'iphonesia', 'iphone']</td>\n",
              "      <td>fingerprint pregnancy test android aps beautiful cute health igers iphoneonly iphonesia iphone</td>\n",
              "      <td>['#fingerprint', '#Pregnancy', '#android', '#apps', '#beautiful', '#cute', '#health', '#igers', '#iphoneonly', '#iphonesia', '#iphone']</td>\n",
              "      <td>#fingerprint #Pregnancy #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone</td>\n",
              "      <td>128</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.923077</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['fingerprint', 'pregnancy', 'test', 'android', 'aps', 'beautiful', 'cute', 'health', 'iger', 'iphone', 'iphones', 'iphone']</td>\n",
              "      <td>fingerprint pregnancy test android aps beautiful cute health iger iphone iphones iphone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/</td>\n",
              "      <td>['finaly', 'transparant', 'silicon', 'case', 'thanks', 'uncle', 'yay', 'sony', 'xperia', 'sonyexperias']</td>\n",
              "      <td>finaly transparant silicon case thanks uncle yay sony xperia sonyexperias</td>\n",
              "      <td>['#yay', '#Sony', '#Xperia', '#S', '#sonyexperias…']</td>\n",
              "      <td>#yay #Sony #Xperia #S #sonyexperias…</td>\n",
              "      <td>131</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.764706</td>\n",
              "      <td>0.091603</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['finaly', 'trans', 'paran', 'silicon', 'case', 'thanks', 'uncle', 'yay', 'sony', 'x', 'peri', 'sony', 'ex', 'peri']</td>\n",
              "      <td>finaly trans paran silicon case thanks uncle yay sony x peri sony ex peri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7918</th>\n",
              "      <td>7918</td>\n",
              "      <td>7919</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Finally got my #smart #pocket #wifi stay connected anytime,anywhere! #ipad and #samsung #s3 #gadget # http://instagr.am/p/U-53G_vJU8/</td>\n",
              "      <td>['finaly', 'got', 'smart', 'pocket', 'wifi', 'stay', 'conected', 'anytimeanywhere', 'ipad', 'samsung', 'gadget']</td>\n",
              "      <td>finaly got smart pocket wifi stay conected anytimeanywhere ipad samsung gadget</td>\n",
              "      <td>['#smart', '#pocket', '#wifi', '#ipad', '#samsung', '#s3', '#gadget', '#']</td>\n",
              "      <td>#smart #pocket #wifi #ipad #samsung #s3 #gadget #</td>\n",
              "      <td>133</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.375000</td>\n",
              "      <td>0.037594</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['finaly', 'got', 'smart', 'pocket', 'wi', 'fi', 'stay', 'conected', 'anytime', 'anywhere', 'ipad', 'samsung', 'gadget']</td>\n",
              "      <td>finaly got smart pocket wi fi stay conected anytime anywhere ipad samsung gadget</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7919</th>\n",
              "      <td>7919</td>\n",
              "      <td>7920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Apple Barcelona!!! #Apple #Store #BCN #Barcelona #travel #iphone #selfie #fly #fun #cabincrew… http://instagram.com/p/wBApVzpCl3/</td>\n",
              "      <td>['aple', 'barcelona', 'aple', 'store', 'bcn', 'barcelona', 'travel', 'iphone', 'selfie', 'fly', 'fun', 'cabincrew']</td>\n",
              "      <td>aple barcelona aple store bcn barcelona travel iphone selfie fly fun cabincrew</td>\n",
              "      <td>['#Apple', '#Store', '#BCN', '#Barcelona', '#travel', '#iphone', '#selfie', '#fly', '#fun', '#cabincrew…']</td>\n",
              "      <td>#Apple #Store #BCN #Barcelona #travel #iphone #selfie #fly #fun #cabincrew…</td>\n",
              "      <td>129</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.093023</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['aple', 'barcelona', 'aple', 'store', 'n', 'barcelona', 'travel', 'iphone', 'self', 'ie', 'fly', 'fun', 'cabin', 'crew']</td>\n",
              "      <td>aple barcelona aple store n barcelona travel iphone self ie fly fun cabin crew</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      index    id  label  \\\n",
              "0         0     1    0.0   \n",
              "1         1     2    0.0   \n",
              "7918   7918  7919    0.0   \n",
              "7919   7919  7920    0.0   \n",
              "\n",
              "                                                                                                                                      tweet  \\\n",
              "0          #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone   \n",
              "1       Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/   \n",
              "7918  Finally got my #smart #pocket #wifi stay connected anytime,anywhere! #ipad and #samsung #s3 #gadget # http://instagr.am/p/U-53G_vJU8/   \n",
              "7919      Apple Barcelona!!! #Apple #Store #BCN #Barcelona #travel #iphone #selfie #fly #fun #cabincrew… http://instagram.com/p/wBApVzpCl3/   \n",
              "\n",
              "                                                                                                                          tweet_lst_clean  \\\n",
              "0     ['fingerprint', 'pregnancy', 'test', 'android', 'aps', 'beautiful', 'cute', 'health', 'igers', 'iphoneonly', 'iphonesia', 'iphone']   \n",
              "1                                ['finaly', 'transparant', 'silicon', 'case', 'thanks', 'uncle', 'yay', 'sony', 'xperia', 'sonyexperias']   \n",
              "7918                     ['finaly', 'got', 'smart', 'pocket', 'wifi', 'stay', 'conected', 'anytimeanywhere', 'ipad', 'samsung', 'gadget']   \n",
              "7919                  ['aple', 'barcelona', 'aple', 'store', 'bcn', 'barcelona', 'travel', 'iphone', 'selfie', 'fly', 'fun', 'cabincrew']   \n",
              "\n",
              "                                                                                         tweet_clean  \\\n",
              "0     fingerprint pregnancy test android aps beautiful cute health igers iphoneonly iphonesia iphone   \n",
              "1                          finaly transparant silicon case thanks uncle yay sony xperia sonyexperias   \n",
              "7918                  finaly got smart pocket wifi stay conected anytimeanywhere ipad samsung gadget   \n",
              "7919                  aple barcelona aple store bcn barcelona travel iphone selfie fly fun cabincrew   \n",
              "\n",
              "                                                                                                                                 hashtags_lst  \\\n",
              "0     ['#fingerprint', '#Pregnancy', '#android', '#apps', '#beautiful', '#cute', '#health', '#igers', '#iphoneonly', '#iphonesia', '#iphone']   \n",
              "1                                                                                        ['#yay', '#Sony', '#Xperia', '#S', '#sonyexperias…']   \n",
              "7918                                                               ['#smart', '#pocket', '#wifi', '#ipad', '#samsung', '#s3', '#gadget', '#']   \n",
              "7919                               ['#Apple', '#Store', '#BCN', '#Barcelona', '#travel', '#iphone', '#selfie', '#fly', '#fun', '#cabincrew…']   \n",
              "\n",
              "                                                                                                   hashtags  \\\n",
              "0     #fingerprint #Pregnancy #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone   \n",
              "1                                                                      #yay #Sony #Xperia #S #sonyexperias…   \n",
              "7918                                                      #smart #pocket #wifi #ipad #samsung #s3 #gadget #   \n",
              "7919                            #Apple #Store #BCN #Barcelona #travel #iphone #selfie #fly #fun #cabincrew…   \n",
              "\n",
              "      total_length  num_words  num_sent  num_unique_words  num_words_title  \\\n",
              "0              128         13         1                13                2   \n",
              "1              131         17         1                17                5   \n",
              "7918           133         16         1                16                1   \n",
              "7919           129         13         1                13                5   \n",
              "\n",
              "      num_uppercase  num_exclamation_marks  num_question_marks  \\\n",
              "0                 5                      0                   0   \n",
              "1                12                      0                   0   \n",
              "7918              5                      1                   0   \n",
              "7919             12                      3                   0   \n",
              "\n",
              "      num_punctuation  num_symbols  num_digits  avg_word_len  avg_uppercase  \\\n",
              "0                   2            0           0      8.923077       0.039062   \n",
              "1                   3            0           0      6.764706       0.091603   \n",
              "7918                3            0           0      7.375000       0.037594   \n",
              "7919                2            0           0      9.000000       0.093023   \n",
              "\n",
              "      avg_unique  \\\n",
              "0            1.0   \n",
              "1            1.0   \n",
              "7918         1.0   \n",
              "7919         1.0   \n",
              "\n",
              "                                                                                                             tweet_lst_clean_emoji  \\\n",
              "0     ['fingerprint', 'pregnancy', 'test', 'android', 'aps', 'beautiful', 'cute', 'health', 'iger', 'iphone', 'iphones', 'iphone']   \n",
              "1             ['finaly', 'trans', 'paran', 'silicon', 'case', 'thanks', 'uncle', 'yay', 'sony', 'x', 'peri', 'sony', 'ex', 'peri']   \n",
              "7918      ['finaly', 'got', 'smart', 'pocket', 'wi', 'fi', 'stay', 'conected', 'anytime', 'anywhere', 'ipad', 'samsung', 'gadget']   \n",
              "7919     ['aple', 'barcelona', 'aple', 'store', 'n', 'barcelona', 'travel', 'iphone', 'self', 'ie', 'fly', 'fun', 'cabin', 'crew']   \n",
              "\n",
              "                                                                            tweet_clean_emoji  \n",
              "0     fingerprint pregnancy test android aps beautiful cute health iger iphone iphones iphone  \n",
              "1                   finaly trans paran silicon case thanks uncle yay sony x peri sony ex peri  \n",
              "7918         finaly got smart pocket wi fi stay conected anytime anywhere ipad samsung gadget  \n",
              "7919           aple barcelona aple store n barcelona travel iphone self ie fly fun cabin crew  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMKpFZEaCOB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "ec134d07-e352-4cf6-848e-bb7a2bbf3c77"
      },
      "source": [
        "display(df_test.head(2).append(df_test.tail(2)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_lst_clean</th>\n",
              "      <th>tweet_clean</th>\n",
              "      <th>hashtags_lst</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>total_length</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_sent</th>\n",
              "      <th>num_unique_words</th>\n",
              "      <th>num_words_title</th>\n",
              "      <th>num_uppercase</th>\n",
              "      <th>num_exclamation_marks</th>\n",
              "      <th>num_question_marks</th>\n",
              "      <th>num_punctuation</th>\n",
              "      <th>num_symbols</th>\n",
              "      <th>num_digits</th>\n",
              "      <th>avg_word_len</th>\n",
              "      <th>avg_uppercase</th>\n",
              "      <th>avg_unique</th>\n",
              "      <th>tweet_lst_clean_emoji</th>\n",
              "      <th>tweet_clean_emoji</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7920</th>\n",
              "      <td>0</td>\n",
              "      <td>7921</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I hate the new #iphone upgrade. Won't let me download apps. #ugh #apple sucks</td>\n",
              "      <td>['hate', 'new', 'iphone', 'upgrade', 'wil', 'let', 'download', 'aps', 'ugh', 'aple', 'suck']</td>\n",
              "      <td>hate new iphone upgrade wil let download aps ugh aple suck</td>\n",
              "      <td>['#iphone', '#ugh', '#apple']</td>\n",
              "      <td>#iphone #ugh #apple</td>\n",
              "      <td>77</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.571429</td>\n",
              "      <td>0.025974</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>['hate', 'new', 'iphone', 'upgrade', 'wil', 'let', 'download', 'aps', 'ugh', 'aple', 'suck']</td>\n",
              "      <td>hate new iphone upgrade wil let download aps ugh aple suck</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7921</th>\n",
              "      <td>1</td>\n",
              "      <td>7922</td>\n",
              "      <td>NaN</td>\n",
              "      <td>currently shitting my fucking pants. #apple #iMac #cashmoney #raddest #swagswagswag http://instagr.am/p/UUIS0bIBZo/</td>\n",
              "      <td>['curently', 'shiting', 'fucking', 'pant', 'aple', 'imac', 'cashmoney', 'radest', 'swagswag']</td>\n",
              "      <td>curently shiting fucking pant aple imac cashmoney radest swagswag</td>\n",
              "      <td>['#apple', '#iMac', '#cashmoney', '#raddest', '#swagswagswag']</td>\n",
              "      <td>#apple #iMac #cashmoney #raddest #swagswagswag</td>\n",
              "      <td>115</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.545455</td>\n",
              "      <td>0.069565</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>['curently', 'shiting', 'fucking', 'pant', 'aple', 'imac', 'cash', 'money', 'rad', 'de', 'st', 'swag', 'wag', 'wag']</td>\n",
              "      <td>curently shiting fucking pant aple imac cash money rad de st swag wag wag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9871</th>\n",
              "      <td>1951</td>\n",
              "      <td>9872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@codeofinterest as i said #Adobe big time we may well as include #apple to</td>\n",
              "      <td>['codeofinterest', 'said', 'adobe', 'big', 'time', 'may', 'wel', 'include', 'aple']</td>\n",
              "      <td>codeofinterest said adobe big time may wel include aple</td>\n",
              "      <td>['#Adobe', '#apple']</td>\n",
              "      <td>#Adobe #apple</td>\n",
              "      <td>74</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.357143</td>\n",
              "      <td>0.013514</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>['code', 'interest', 'said', 'adobe', 'big', 'time', 'may', 'wel', 'include', 'aple']</td>\n",
              "      <td>code interest said adobe big time may wel include aple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9872</th>\n",
              "      <td>1952</td>\n",
              "      <td>9873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Finally I got it .. thanx my father .. #Samsung #galaxy #s3 #gift #father #phone #new http://instagr.am/p/NoxkiPE</td>\n",
              "      <td>['finaly', 'got', 'thanx', 'father', 'samsung', 'galaxy', 'gift', 'father', 'phone', 'new']</td>\n",
              "      <td>finaly got thanx father samsung galaxy gift father phone new</td>\n",
              "      <td>['#Samsung', '#galaxy', '#s3', '#gift', '#father', '#phone', '#new']</td>\n",
              "      <td>#Samsung #galaxy #s3 #gift #father #phone #new</td>\n",
              "      <td>113</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.705882</td>\n",
              "      <td>0.053097</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>['finaly', 'got', 'x', 'father', 'samsung', 'galaxy', 'gift', 'father', 'phone', 'new']</td>\n",
              "      <td>finaly got x father samsung galaxy gift father phone new</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      index    id  label  \\\n",
              "7920      0  7921    NaN   \n",
              "7921      1  7922    NaN   \n",
              "9871   1951  9872    NaN   \n",
              "9872   1952  9873    NaN   \n",
              "\n",
              "                                                                                                                    tweet  \\\n",
              "7920                                        I hate the new #iphone upgrade. Won't let me download apps. #ugh #apple sucks   \n",
              "7921  currently shitting my fucking pants. #apple #iMac #cashmoney #raddest #swagswagswag http://instagr.am/p/UUIS0bIBZo/   \n",
              "9871                                           @codeofinterest as i said #Adobe big time we may well as include #apple to   \n",
              "9872    Finally I got it .. thanx my father .. #Samsung #galaxy #s3 #gift #father #phone #new http://instagr.am/p/NoxkiPE   \n",
              "\n",
              "                                                                                    tweet_lst_clean  \\\n",
              "7920   ['hate', 'new', 'iphone', 'upgrade', 'wil', 'let', 'download', 'aps', 'ugh', 'aple', 'suck']   \n",
              "7921  ['curently', 'shiting', 'fucking', 'pant', 'aple', 'imac', 'cashmoney', 'radest', 'swagswag']   \n",
              "9871            ['codeofinterest', 'said', 'adobe', 'big', 'time', 'may', 'wel', 'include', 'aple']   \n",
              "9872    ['finaly', 'got', 'thanx', 'father', 'samsung', 'galaxy', 'gift', 'father', 'phone', 'new']   \n",
              "\n",
              "                                                            tweet_clean  \\\n",
              "7920         hate new iphone upgrade wil let download aps ugh aple suck   \n",
              "7921  curently shiting fucking pant aple imac cashmoney radest swagswag   \n",
              "9871            codeofinterest said adobe big time may wel include aple   \n",
              "9872       finaly got thanx father samsung galaxy gift father phone new   \n",
              "\n",
              "                                                              hashtags_lst  \\\n",
              "7920                                         ['#iphone', '#ugh', '#apple']   \n",
              "7921        ['#apple', '#iMac', '#cashmoney', '#raddest', '#swagswagswag']   \n",
              "9871                                                  ['#Adobe', '#apple']   \n",
              "9872  ['#Samsung', '#galaxy', '#s3', '#gift', '#father', '#phone', '#new']   \n",
              "\n",
              "                                            hashtags  total_length  num_words  \\\n",
              "7920                             #iphone #ugh #apple            77         14   \n",
              "7921  #apple #iMac #cashmoney #raddest #swagswagswag           115         11   \n",
              "9871                                   #Adobe #apple            74         14   \n",
              "9872  #Samsung #galaxy #s3 #gift #father #phone #new           113         17   \n",
              "\n",
              "      num_sent  num_unique_words  num_words_title  num_uppercase  \\\n",
              "7920         1                14                1              2   \n",
              "7921         1                11                0              8   \n",
              "9871         1                13                1              1   \n",
              "9872         1                16                3              6   \n",
              "\n",
              "      num_exclamation_marks  num_question_marks  num_punctuation  num_symbols  \\\n",
              "7920                      0                   0                2            0   \n",
              "7921                      0                   0                3            0   \n",
              "9871                      0                   0                0            0   \n",
              "9872                      0                   0                6            0   \n",
              "\n",
              "      num_digits  avg_word_len  avg_uppercase  avg_unique  \\\n",
              "7920           0      4.571429       0.025974    1.000000   \n",
              "7921           0      9.545455       0.069565    1.000000   \n",
              "9871           0      4.357143       0.013514    0.928571   \n",
              "9872           0      5.705882       0.053097    0.941176   \n",
              "\n",
              "                                                                                                     tweet_lst_clean_emoji  \\\n",
              "7920                          ['hate', 'new', 'iphone', 'upgrade', 'wil', 'let', 'download', 'aps', 'ugh', 'aple', 'suck']   \n",
              "7921  ['curently', 'shiting', 'fucking', 'pant', 'aple', 'imac', 'cash', 'money', 'rad', 'de', 'st', 'swag', 'wag', 'wag']   \n",
              "9871                                 ['code', 'interest', 'said', 'adobe', 'big', 'time', 'may', 'wel', 'include', 'aple']   \n",
              "9872                               ['finaly', 'got', 'x', 'father', 'samsung', 'galaxy', 'gift', 'father', 'phone', 'new']   \n",
              "\n",
              "                                                              tweet_clean_emoji  \n",
              "7920                 hate new iphone upgrade wil let download aps ugh aple suck  \n",
              "7921  curently shiting fucking pant aple imac cash money rad de st swag wag wag  \n",
              "9871                     code interest said adobe big time may wel include aple  \n",
              "9872                   finaly got x father samsung galaxy gift father phone new  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL4SBgfWGTHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42ab1157-da62-4653-f7c6-d3a1db83da0c"
      },
      "source": [
        "df_train['tweet_clean'].apply(len).min()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9pymaJVAcX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49dfb44a-b6f6-45bb-804b-b86eea858410"
      },
      "source": [
        "neptune.create_experiment(\n",
        "    name='ktrain', # put small name\n",
        "    description='',\n",
        "    tags = ['ktrain', 'bert'],\n",
        "    upload_source_files=None\n",
        ")\n",
        "\n",
        "neptune.log_text('versions_dl', str(versions_dl))\n",
        "neptune.log_text('versions_ds', str(versions_ds))\n",
        "\n",
        "neptune.log_text('text processing', 'various maxlen and epochs')\n",
        "\n",
        "maincol = 'tweet_clean' # best so far: 'tweet'\n",
        "neptune.log_text('column_used', maincol)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://ui.neptune.ai/bhishanpdl/twitter-sentiment-analysis/e/TWITSENT-15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_OKcdoZwTco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "7665b2a1-6b57-47c5-c028-00f640f01091"
      },
      "source": [
        "%%time\n",
        "\n",
        "time_start = time.time()\n",
        "# bert is uncased_L-12_H-768_A-12.zip\n",
        "# distilbert gives error\n",
        "\n",
        "\n",
        "# Parameters\n",
        "MODEL_NAME = 'bert'\n",
        "PARAMS = dict()\n",
        "PARAMS['ngram_range'] = 1\n",
        "PARAMS['max_features'] = 20000\n",
        "PARAMS['maxlen'] = 300\n",
        "\n",
        "neptune.log_text('model_name', MODEL_NAME)\n",
        "for k,v in PARAMS.items():\n",
        "    neptune.log_metric(k,v)\n",
        "\n",
        "(X_train, y_train), (X_valid, y_valid), preproc = \\\n",
        "ktrain.text.texts_from_df(df_train,\n",
        "    text_column     = maincol,\n",
        "    label_columns   = [target],\n",
        "    random_state    = SEED,\n",
        "    ngram_range     = PARAMS['ngram_range'] ,\n",
        "    max_features    = PARAMS['max_features'],\n",
        "    val_df          = None, # if not 10% of train is used\n",
        "    maxlen          = PARAMS['maxlen'], # it was 500\n",
        "    preprocess_mode = MODEL_NAME)\n",
        "\n",
        "model = ktrain.text.text_classifier(name=MODEL_NAME,\n",
        "                             train_data=(X_train, y_train),\n",
        "                             metrics=['accuracy'],\n",
        "                             preproc=preproc)\n",
        "\n",
        "learner = ktrain.get_learner(model=model,\n",
        "                             train_data=(X_train, y_train),\n",
        "                             val_data=(X_valid, y_valid),\n",
        "                             batch_size=6)\n",
        "\n",
        "PARAMS_ONECYCLE = {\n",
        "    'lr'    : 2e-5, # original value is 2e-5\n",
        "    'epochs': 5 # best so far was 5\n",
        "    }\n",
        "\n",
        "for k,v in PARAMS_ONECYCLE.items():\n",
        "    neptune.log_metric(k,v)\n",
        "\n",
        "learner.fit_onecycle(**PARAMS_ONECYCLE )\n",
        "\n",
        "time_taken = time.time() - time_start\n",
        "m,s = divmod(time_taken,60)\n",
        "neptune.log_metric('time_taken_min', m)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 300\n",
            "done.\n",
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Epoch 1/5\n",
            "1188/1188 [==============================] - 797s 671ms/step - loss: 0.3380 - accuracy: 0.8450 - val_loss: 0.2213 - val_accuracy: 0.9053\n",
            "Epoch 2/5\n",
            "1188/1188 [==============================] - 790s 665ms/step - loss: 0.2325 - accuracy: 0.9003 - val_loss: 0.2186 - val_accuracy: 0.9091\n",
            "Epoch 3/5\n",
            "1188/1188 [==============================] - 787s 662ms/step - loss: 0.1784 - accuracy: 0.9324 - val_loss: 0.2130 - val_accuracy: 0.9179\n",
            "Epoch 4/5\n",
            "1188/1188 [==============================] - 785s 661ms/step - loss: 0.0885 - accuracy: 0.9689 - val_loss: 0.2753 - val_accuracy: 0.9116\n",
            "Epoch 5/5\n",
            "1188/1188 [==============================] - 784s 660ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 0.4086 - val_accuracy: 0.9104\n",
            "CPU times: user 58min 50s, sys: 12min 28s, total: 1h 11min 19s\n",
            "Wall time: 1h 6min 7s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tWRYXPfDpim",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "d75424d8-a166-4ad2-a87e-bfd8edf94ab9"
      },
      "source": [
        "%%time\n",
        "\n",
        "from neptunecontrib.api import log_table\n",
        "\n",
        "time_start = time.time()\n",
        "valid_probs2d = learner.predict(val_data=(X_valid,y_valid))\n",
        "valid_preds = (valid_probs2d[:,1]>0.5).astype(int).tolist()\n",
        "lst_y_valid = (y_valid[:,1].tolist())\n",
        "\n",
        "text_model_name = \"bert\"\n",
        "params = str(PARAMS)\n",
        "model_name = \"\"\n",
        "desc = \"\"\n",
        "\n",
        "yvd = lst_y_valid\n",
        "vd_preds = valid_preds\n",
        "\n",
        "acc = metrics.accuracy_score(yvd,vd_preds)\n",
        "pre = metrics.precision_score(yvd,vd_preds)\n",
        "rec = metrics.recall_score(yvd,vd_preds)\n",
        "f1 = metrics.f1_score(yvd,vd_preds,average='weighted')\n",
        "\n",
        "row = [text_model_name, params, model_name,desc]\n",
        "row = row + [acc, pre, rec, f1]\n",
        "\n",
        "df_eval.loc[len(df_eval)] = row\n",
        "df_eval = df_eval.drop_duplicates(subset=['Text Model', 'Params', 'Model', 'Description'])\n",
        "\n",
        "# log the validation results\n",
        "log_table('df_eval', df_eval)\n",
        "dic_results = {'acc':acc,\n",
        "               'precision':pre,\n",
        "               'recall':rec,\n",
        "               'f1': f1}\n",
        "\n",
        "for k,v in dic_results.items():\n",
        "    print('valid_'+k, v)\n",
        "    neptune.log_metric('valid_'+k, v)\n",
        "\n",
        "time_taken = time.time() - time_start\n",
        "m,s = divmod(time_taken,60)\n",
        "neptune.log_metric('time_taken_validation_min', m)\n",
        "\n",
        "display(df_eval)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "valid_acc 0.9103535353535354\n",
            "valid_precision 0.7904761904761904\n",
            "valid_recall 0.8601036269430051\n",
            "valid_f1 0.9115991300375775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text Model</th>\n",
              "      <th>Params</th>\n",
              "      <th>Model</th>\n",
              "      <th>Description</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bert</td>\n",
              "      <td>{'lr': 2e-05, 'epochs': 5}</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.812808</td>\n",
              "      <td>0.854922</td>\n",
              "      <td>0.917368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bert</td>\n",
              "      <td>{'ngram_range': 1, 'max_features': 20000, 'maxlen': 300}</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.910354</td>\n",
              "      <td>0.790476</td>\n",
              "      <td>0.860104</td>\n",
              "      <td>0.911599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Text Model                                                    Params Model  \\\n",
              "0       bert                                {'lr': 2e-05, 'epochs': 5}         \n",
              "1       bert  {'ngram_range': 1, 'max_features': 20000, 'maxlen': 300}         \n",
              "\n",
              "  Description  Accuracy  Precision    Recall        F1  \n",
              "0              0.916667   0.812808  0.854922  0.917368  \n",
              "1              0.910354   0.790476  0.860104  0.911599  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.43 s, sys: 831 ms, total: 6.26 s\n",
            "Wall time: 29.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsMBChxhz47P",
        "colab_type": "text"
      },
      "source": [
        "# Model Prediction on Test data using ktrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDoWI5760EjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "462f914a-d399-4bef-b84e-d32932818afb"
      },
      "source": [
        "%%time\n",
        "predictor = ktrain.get_predictor(learner.model, preproc)\n",
        "X_test = df_test[maincol].to_numpy()\n",
        "test_preds = predictor.predict(X_test,return_proba=False)\n",
        "df_test[target] = test_preds\n",
        "\n",
        "df_sub = df_test[['id','label']]\n",
        "df_sub['label'] = df_sub['label'].replace({'not_label': 0, 'label': 1})\n",
        "\n",
        "df_sub.to_csv('sub_ktrain_tweet_clean_bert_epochs5_maxlen300.csv', index=False)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.04 s, sys: 2.11 s, total: 7.15 s\n",
            "Wall time: 51.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT4ZC3D7zYOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upload the data and get the score\n",
        "neptune.log_metric('test_f1', 0.877973006703751 )"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFR5TD3ZzdX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_so_far = \"\"\"\n",
        "bert lr=2e-5 epochs=5 ngram_range=1 maxlen=300\n",
        "f1 = 0.908687336005899\n",
        "\n",
        "n_gram=2 gave worse result\n",
        "tweet_clean_emoji gave worse result\n",
        "\n",
        "bert lr=2e-5 epochs=5 ngram_range=1 maxlen=400 \n",
        "f1 = 0.908265806079951\n",
        "\n",
        "bert lr=2e-5 epochs=5 ngram_range=1 maxlen=300 maincol=tweet_clean\n",
        "f1=0.877973006703751\n",
        "\n",
        "\"\"\"\n",
        "neptune.log_text('best_so_far',\n",
        "                 best_so_far)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duv3gXzFeir2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}