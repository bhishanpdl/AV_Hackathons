{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "d02_sentiment_analysis_transformers_distilbert_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d711699cfb64f4ca19267428bf8aa41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1e6ab8710d0f43e2bf49fd7d54f3bb44",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9a418865afd14790871c464713ca21c3",
              "IPY_MODEL_213cf0371b3145348139876f300e3aa8"
            ]
          }
        },
        "1e6ab8710d0f43e2bf49fd7d54f3bb44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a418865afd14790871c464713ca21c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_76d42f03548e4c78af2cc3319c7d8dd3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 363423424,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 363423424,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22a8e7a3b1334175bcb1a232d9424b12"
          }
        },
        "213cf0371b3145348139876f300e3aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_556ed37ce16e4c8f9a47181c4b7a8eb7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 363M/363M [00:23&lt;00:00, 15.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d8adf415d8549d289d1e7b010624a1e"
          }
        },
        "76d42f03548e4c78af2cc3319c7d8dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22a8e7a3b1334175bcb1a232d9424b12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "556ed37ce16e4c8f9a47181c4b7a8eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d8adf415d8549d289d1e7b010624a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT8ruEvhSIFl",
        "colab_type": "text"
      },
      "source": [
        "# Description\n",
        "# Descriptions\n",
        "- BERT stands for Bidirectional Encoder Representations from Transformers\n",
        "- BERT was developed by researchers at Google in 2018\n",
        "- BERT is a text representation technique like Word Embeddings.\n",
        "\n",
        "Ref: https://www.kaggle.com/madz2000/sentiment-analysis-cleaning-eda-bert-88-acc\n",
        "\n",
        "BERT WORKING\n",
        "BERT relies on a Transformer (the attention mechanism that learns contextual relationships between words in a text). A basic Transformer consists of an encoder to read the text input and a decoder to produce a prediction for the task. Since BERT’s goal is to generate a language representation model, it only needs the encoder part. The input to the encoder for BERT is a sequence of tokens, which are first converted into vectors and then processed in the neural network. But before processing can start, BERT needs the input to be massaged and decorated with some extra metadata:\n",
        "\n",
        "1. Token embeddings: A `[CLS]` token is added to the input word tokens at the beginning of the first sentence and a `[SEP]` token is inserted at the end of each sentence.\n",
        "\n",
        "2. Segment embeddings: A marker indicating Sentence A or Sentence B is added to each token. This allows the encoder to distinguish between sentences.\n",
        "\n",
        "3. Positional embeddings: A positional embedding is added to each token to indicate its position in the sentence.\n",
        "\n",
        "Ref: https://towardsml.com/2019/09/17/bert-explained-a-complete-guide-with-theory-and-tutorial/\n",
        "\n",
        "![](../images/bert_example.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4lP0xs55MuL",
        "colab_type": "text"
      },
      "source": [
        "# Load the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBbeTrGJ5Hk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "# capture will not print in notebook\n",
        "\n",
        "import os\n",
        "import sys\n",
        "ENV_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if ENV_COLAB:\n",
        "    ## install modules\n",
        "    !pip install tokenizers\n",
        "    !pip install transformers\n",
        "    !pip install scikit-plot\n",
        "\n",
        "    ## print\n",
        "    print('Environment: Google Colaboratory.')\n",
        "\n",
        "# NOTE: If we update modules in gcolab, we need to restart runtime."
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvFvBLJV0Dkv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "4915eebf-2da6-4d92-e31c-5935db6753b5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# settings\n",
        "pd.set_option('max_colwidth',200)\n",
        "pd.set_option('max_columns',200)\n",
        "SEED = 100\n",
        "\n",
        "# ml\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# nlp\n",
        "import re\n",
        "\n",
        "# extra\n",
        "import sys\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "# deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM,Dense,Bidirectional,Input\n",
        "import torch\n",
        "import transformers\n",
        "import tokenizers\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "# versions\n",
        "pprint([(x.__name__,x.__version__) for x in\n",
        "        [np,pd,sklearn,tf,keras,torch,transformers,tokenizers]])\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('numpy', '1.18.5'),\n",
            " ('pandas', '1.0.5'),\n",
            " ('sklearn', '0.22.2.post1'),\n",
            " ('tensorflow', '2.3.0'),\n",
            " ('keras', '2.4.3'),\n",
            " ('torch', '1.6.0+cu101'),\n",
            " ('transformers', '3.1.0'),\n",
            " ('tokenizers', '0.8.1.rc2')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ-42fh0hjsF",
        "colab_type": "text"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyoj29J24hPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "41033b58-45ea-4215-d941-ab350d6a4f39"
      },
      "source": [
        "df = pd.read_csv('https://github.com/bhishanpdl/Datasets/blob/master/janatahack/sentiment_analysis/raw/train.csv?raw=true')\n",
        "\n",
        "df = df.iloc[:1000] # to prevent OOM\n",
        "\n",
        "print(f\"train : {df.shape}\")\n",
        "display(df.head(2).append(df.tail(2)))\n",
        "\n",
        "target = 'label'\n",
        "maincol = 'tweet'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train : (1000, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>999</td>\n",
              "      <td>1</td>\n",
              "      <td>Idk if I should download Dead Nation and inFAMOUS and never play either one, or just not download anything #Sony #PSN #Playstation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1000</td>\n",
              "      <td>1</td>\n",
              "      <td>I've gone thru four iPhone chargers in 3 days #boss #badass</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  label  \\\n",
              "0       1      0   \n",
              "1       2      0   \n",
              "998   999      1   \n",
              "999  1000      1   \n",
              "\n",
              "                                                                                                                                   tweet  \n",
              "0       #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone  \n",
              "1    Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/  \n",
              "998   Idk if I should download Dead Nation and inFAMOUS and never play either one, or just not download anything #Sony #PSN #Playstation  \n",
              "999                                                                          I've gone thru four iPhone chargers in 3 days #boss #badass  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFYqpVVOTMvU",
        "colab_type": "text"
      },
      "source": [
        "# Text Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du1oL858TQ9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maincol = 'tweet'\n",
        "target = 'label'\n",
        "mc = maincol + '_clean'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR_IyXiHTSrb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "9ecb811e-db1f-4df0-fe18-97a6800572fd"
      },
      "source": [
        "import re\n",
        "def process_text(text):\n",
        "    out = re.sub(r'<[^>]+>','', text) # remove html tags\n",
        "    out = re.sub('[^a-zA-Z]', ' ', out) # keep only alpha\n",
        "    out = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', out) # remove single letter\n",
        "    out = re.sub(r'\\s+', ' ', out) # remove multiple spaces\n",
        "\n",
        "    return out\n",
        "\n",
        "s = pd.Series(df[maincol][1])\n",
        "s.progress_apply(process_text)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 494.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Finally transparant silicon case Thanks to my uncle yay Sony Xperia sonyexperias http instagram com YGEt JC JM \n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNWSTVzYUH1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7131976-494c-4fbc-8f32-539f419b5c07"
      },
      "source": [
        "df[mc] = df[maincol].progress_apply(process_text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 33723.32it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck0JjuVCUJgD",
        "colab_type": "text"
      },
      "source": [
        "# Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-hbhOyLUXhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4JhM3OTUZxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ser_Xtrain, ser_Xtest, ser_ytrain, ser_ytest = train_test_split(df[mc],df[target],\n",
        "                                                shuffle=True,\n",
        "                                                random_state=SEED,\n",
        "                                                stratify = df[target])\n",
        "\n",
        "Xtrain = ser_Xtrain.to_numpy().ravel()\n",
        "Xtest = ser_Xtest.to_numpy().ravel()\n",
        "\n",
        "ytrain = ser_ytrain.to_numpy().ravel()\n",
        "ytest = ser_ytest.to_numpy().ravel()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2-jhqiAUuQr",
        "colab_type": "text"
      },
      "source": [
        "# Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHPX9w5dU4-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f368837a-b200-4bd4-dd43-f17c72c12d1c"
      },
      "source": [
        "import transformers\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "class_tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased' ,\n",
        "                                                             lower = True)\n",
        "# Save the loaded tokenizer locally\n",
        "class_tokenizer.save_pretrained('.')\n",
        "\n",
        "# Reload it with the huggingface tokenizers library\n",
        "tokenizer = BertWordPieceTokenizer('vocab.txt', lowercase=True)\n",
        "tokenizer"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tokenizer(vocabulary_size=30522, model=BertWordPiece, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], pad_token=[PAD], mask_token=[MASK], clean_text=True, handle_chinese_chars=True, strip_accents=None, lowercase=True, wordpieces_prefix=##)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POL4mayIVvQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pprint([i for i in dir(tokenizer) if i[0]!='_'],max_seq_len=80)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCp0IPwZYYhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_encode(texts, tokenizer, chunk_size=256, maxlen=400):\n",
        "\n",
        "    tokenizer.enable_truncation(max_length=maxlen)\n",
        "    tokenizer.enable_padding()\n",
        "    all_ids = []\n",
        "    \n",
        "    for i in range(0, len(texts), chunk_size):\n",
        "        text_chunk = texts[i:i+chunk_size].tolist()\n",
        "        encs = tokenizer.encode_batch(text_chunk)\n",
        "        all_ids.extend([enc.ids for enc in encs])\n",
        "    \n",
        "    return np.array(all_ids)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1Rw4YNbY5f7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain = do_encode(Xtrain, tokenizer, maxlen=400)\n",
        "Xtest = do_encode(Xtest, tokenizer, maxlen=400)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8ZdolzlZGoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input,Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "\n",
        "def build_model(transformer, max_len=400):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    sequence_output = transformer(input_word_ids)[0]\n",
        "    cls_token = sequence_output[:, 0, :]\n",
        "    out = Dense(1, activation='sigmoid')(cls_token)\n",
        "\n",
        "    model = Model(inputs=input_word_ids, outputs=out)\n",
        "    model.compile(Adam(lr=2e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUduF-BKZ_A8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175,
          "referenced_widgets": [
            "9d711699cfb64f4ca19267428bf8aa41",
            "1e6ab8710d0f43e2bf49fd7d54f3bb44",
            "9a418865afd14790871c464713ca21c3",
            "213cf0371b3145348139876f300e3aa8",
            "76d42f03548e4c78af2cc3319c7d8dd3",
            "22a8e7a3b1334175bcb1a232d9424b12",
            "556ed37ce16e4c8f9a47181c4b7a8eb7",
            "2d8adf415d8549d289d1e7b010624a1e"
          ]
        },
        "outputId": "ade03a10-1f73-4c5d-ff1b-fe84891e8584"
      },
      "source": [
        "bert_model = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d711699cfb64f4ca19267428bf8aa41",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=363423424.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_projector', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAUNj0UhaDD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "3a77a973-77f8-48b5-d51f-15b604d8d3e3"
      },
      "source": [
        "model = build_model(bert_model, max_len=400)\n",
        "model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_word_ids (InputLayer)  [(None, 400)]             0         \n",
            "_________________________________________________________________\n",
            "tf_distil_bert_model (TFDist ((None, 400, 768),)       66362880  \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice_1  [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 769       \n",
            "=================================================================\n",
            "Total params: 66,363,649\n",
            "Trainable params: 66,363,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAt-D-IkaNzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(Xtest)\n",
        "y_pred = np.round(y_pred).astype(int)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1fkBjWJa_zj",
        "colab_type": "text"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Utwu5XGZcWB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG6B3pAkbW8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_eval = pd.DataFrame({\n",
        "    'Text Model': [],\n",
        "    'Params': [],\n",
        "    'Model': [],\n",
        "    'Description': [],\n",
        "    'Accuracy': [],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'F1': [],\n",
        "})\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXvUGTyKc3lY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "f52cd661-99b5-4608-a904-75a0446ba600"
      },
      "source": [
        "text_model_name = \"distilbert\"\n",
        "params = \"distilbert-base-uncased\"\n",
        "model_name = \"keras\"\n",
        "desc = \"dense layer=1, Adam(lr=2e-5)\"\n",
        "\n",
        "Xvd = Xtest\n",
        "yvd = ytest\n",
        "vd_preds = y_pred\n",
        "\n",
        "acc = metrics.accuracy_score(yvd,vd_preds)\n",
        "pre = metrics.precision_score(yvd,vd_preds)\n",
        "rec = metrics.recall_score(yvd,vd_preds)\n",
        "f1 = metrics.f1_score(yvd,vd_preds,average='weighted')\n",
        "\n",
        "row = [text_model_name, params, model_name,desc]\n",
        "row = row + [acc, pre, rec, f1]\n",
        "\n",
        "df_eval.loc[len(df_eval)] = row\n",
        "df_eval = df_eval.drop_duplicates(subset=['Text Model', 'Params', 'Model', 'Description'])\n",
        "\n",
        "df_eval"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text Model</th>\n",
              "      <th>Params</th>\n",
              "      <th>Model</th>\n",
              "      <th>Description</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>distilbert</td>\n",
              "      <td>distilbert-base-uncased</td>\n",
              "      <td>keras</td>\n",
              "      <td>dense layer=1, Adam(lr=2e-5)</td>\n",
              "      <td>0.684</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.663583</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Text Model                   Params  Model                   Description  \\\n",
              "0  distilbert  distilbert-base-uncased  keras  dense layer=1, Adam(lr=2e-5)   \n",
              "\n",
              "   Accuracy  Precision    Recall        F1  \n",
              "0     0.684   0.318182  0.222222  0.663583  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xfry0Qncdaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}